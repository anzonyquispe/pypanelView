{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import patsy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from patsy import dmatrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c202c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if formula is not None:\n",
    "    def check_and_modify_formula(formula):\n",
    "        # Split the formula into left-hand side (LHS) and right-hand side (RHS)\n",
    "        lhs, rhs = formula.split(\"~\")\n",
    "\n",
    "        # Check if there is a '1' in the RHS\n",
    "        if '1' in rhs.strip():\n",
    "            return formula\n",
    "        else:\n",
    "            # Add '-1' if '1' is not found in the RHS\n",
    "            modified_formula = f\"{lhs.strip()} ~ {rhs.strip()} -1\"\n",
    "            return modified_formula  # Return the modified formula\n",
    "    formula = check_and_modify_formula(formula)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d511f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/lwrzx5hs7d3cxk4p5zsy7zqh0000gp/T/ipykernel_22832/327656139.py:6: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[index[0]]):\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame if needed\n",
    "if not isinstance(data, pd.DataFrame):\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "# Convert index to string or numeric depending on the content\n",
    "if pd.api.types.is_categorical_dtype(data[index[0]]):\n",
    "    if pd.to_numeric(data[index[0]], errors='coerce').isna().sum() > 0:  # Contains text\n",
    "        data[index[0]] = data[index[0]].astype(str)\n",
    "    else:  # Contains numbers\n",
    "        data[index[0]] = pd.to_numeric(data[index[0]].cat.codes, errors='coerce')\n",
    "\n",
    "# Number of unique units\n",
    "N0 = data[index[0]].nunique()\n",
    "\n",
    "if N0 <= 500:\n",
    "    if collapse_history is None:\n",
    "        collapse_history = False\n",
    "    else:\n",
    "        collapse_history = collapse_history\n",
    "\n",
    "    if display_all is None:\n",
    "        display_all = False\n",
    "    else:\n",
    "        display_all = display_all\n",
    "else:\n",
    "    if collapse_history is not None:\n",
    "        if display_all is None:\n",
    "            display_all = False\n",
    "        else:\n",
    "            display_all = display_all\n",
    "    else:\n",
    "        if display_all is None:\n",
    "            if type != \"outcome\":\n",
    "                collapse_history = True\n",
    "                display_all = False\n",
    "            else:\n",
    "                collapse_history = False\n",
    "                display_all = False\n",
    "        else:\n",
    "            collapse_history = False\n",
    "\n",
    "\n",
    "\n",
    "# Check if 'leave_gap' is logical or in [0, 1]\n",
    "if not isinstance(leave_gap, bool) and leave_gap not in [0, 1]:\n",
    "    raise ValueError('\"leave_gap\" is not a logical flag.')\n",
    "\n",
    "# Check if 'by_cohort' is logical or in [0, 1]\n",
    "if not isinstance(by_cohort, bool) and by_cohort not in [0, 1]:\n",
    "    raise ValueError('\"by_cohort\" is not a logical flag.')\n",
    "\n",
    "# Check if 'display_all' is logical or in [0, 1]\n",
    "if not isinstance(display_all, bool) and display_all not in [0, 1]:\n",
    "    raise ValueError('\"display_all\" is not a logical flag.')\n",
    "\n",
    "# Check if 'by_group_side' is logical or in [0, 1]\n",
    "if not isinstance(by_group_side, bool) and by_group_side not in [0, 1]:\n",
    "    raise ValueError('\"by_group_side\" is not a logical flag.')\n",
    "\n",
    "# Check if 'by_unit' is logical or in [0, 1]\n",
    "if not isinstance(by_unit, bool) and by_unit not in [0, 1]:\n",
    "    raise ValueError('\"by_unit\" is not a logical flag.')\n",
    "\n",
    "# Check if 'axis_adjust' is logical or in [0, 1]\n",
    "if not isinstance(axis_adjust, bool) and axis_adjust not in [0, 1]:\n",
    "    raise ValueError('\"axis_adjust\" is not a logical flag.')\n",
    "\n",
    "# Check if 'axis_lab_angle' is numeric and within [0, 90]\n",
    "if axis_lab_angle is not None:\n",
    "    if not isinstance(axis_lab_angle, (int, float)):\n",
    "        raise ValueError('\"axis_lab_angle\" must be numeric.')\n",
    "    elif axis_lab_angle < 0 or axis_lab_angle > 90:\n",
    "        raise ValueError('\"axis_lab_angle\" needs to be in [0, 90].')\n",
    "\n",
    "\n",
    "\n",
    "# pre_post\n",
    "if pre_post is None:\n",
    "    if type == \"outcome\":\n",
    "        pre_post = True\n",
    "    else:\n",
    "        pre_post = False\n",
    "\n",
    "if not isinstance(pre_post, bool) and pre_post not in [0, 1]:\n",
    "    raise ValueError('\"pre_post\" is not a logical flag.')\n",
    "\n",
    "# theme_bw\n",
    "if not isinstance(theme_bw, bool) and theme_bw not in [0, 1]:\n",
    "    raise ValueError('\"theme_bw\" is not a logical flag.')\n",
    "\n",
    "# by_timing\n",
    "if not isinstance(by_timing, bool) and by_timing not in [0, 1]:\n",
    "    raise ValueError('\"by_timing\" is not a logical flag.')\n",
    "\n",
    "# by_group\n",
    "if not isinstance(by_group, bool) and by_group not in [0, 1]:\n",
    "    raise ValueError('\"by_group\" is not a logical flag.')\n",
    "\n",
    "# ignore_treat\n",
    "if not isinstance(ignore_treat, bool) and ignore_treat not in [0, 1]:\n",
    "    raise ValueError('\"ignore_treat\" is not a logical flag.')\n",
    "\n",
    "# Ensure that 'by_group_side' implies 'by_group'\n",
    "if by_group_side:\n",
    "    if not by_group:\n",
    "        by_group = True\n",
    "\n",
    "# Warning for 'by_group' and 'by_cohort' combination\n",
    "if by_group:\n",
    "    if by_cohort is not None:\n",
    "        print('Warning: \"by_cohort\" is not allowed with \"by_group = True\" or \"by_group_side = True\". Ignored.')\n",
    "        by_cohort = None  # Ignoring 'by_cohort'\n",
    "\n",
    "# Handle 'type = missing' and 'ignore_treat'\n",
    "if type in [\"missing\", \"miss\"]:\n",
    "    if ignore_treat:\n",
    "        raise ValueError('Option \"type = missing\" should not be combined with \"ignore_treat = True\".')\n",
    "\n",
    "# Check combination of 'by_cohort' and 'type'\n",
    "if type != \"outcome\" and by_cohort:\n",
    "    raise ValueError('Option \"by_cohort = True\" should be combined with \"type = \\'outcome\\'\".')\n",
    "\n",
    "# Check combination of 'type = outcome' and 'collapse_history'\n",
    "if type == \"outcome\" and collapse_history:\n",
    "    raise ValueError('Option \"collapse_history = True\" should not be combined with \"type = \\'outcome\\'\".')\n",
    "\n",
    "# Handling the formula logic\n",
    "if formula is not None:  # with formula\n",
    "    \n",
    "    yvalue, xvalues = dmatrices(formula, data, return_type='dataframe')\n",
    "    data = pd.concat([data[index], yvalue, xvalues], axis = 1)\n",
    "\n",
    "\n",
    "    # Check if the formula starts with \"~\"\n",
    "    if formula.split(\"~\")[0] == \"\":\n",
    "        raise ValueError('You need to specify \"Y\"/\"D\"/\"X\" or provide a proper \"formula\".')\n",
    "\n",
    "    # Parse the formula\n",
    "    varnames = patsy.ModelDesc.from_formula(formula).lhs_termlist + patsy.ModelDesc.from_formula(formula).rhs_termlist\n",
    "    varnames = [v.name() for v in varnames]  # Convert to strings\n",
    "\n",
    "    Y = varnames[0]  # Left-hand side of the formula\n",
    "\n",
    "    if not isinstance(Y, (int, float)):  # Y is a variable (not a number)\n",
    "        # Outcome\n",
    "        Y = varnames[0]\n",
    "\n",
    "        # Treatment indicator and covariates\n",
    "        if len(varnames) == 1:  # Only Y\n",
    "            D = X = None\n",
    "            ignore_treat = 1\n",
    "\n",
    "            if type == \"treat\":  # Y ~ 1, type(treat)\n",
    "                print('\"type = treat\" not allowed. Plot \"type = missing\" instead.')\n",
    "                type = \"missing\"\n",
    "\n",
    "        elif len(varnames) == 2:\n",
    "            if ignore_treat == 0:\n",
    "                D = varnames[1]\n",
    "                X = None\n",
    "            else:\n",
    "                D = None\n",
    "                X = varnames[1]\n",
    "\n",
    "        else:  # len(varnames) > 2\n",
    "            if ignore_treat == 0:\n",
    "                D = varnames[1]\n",
    "                X = varnames[2:]\n",
    "            else:\n",
    "                D = None\n",
    "                X = varnames[1:]\n",
    "\n",
    "    elif isinstance(Y, (int, float)):  # Y is a number\n",
    "        # Outcome\n",
    "        Y = None\n",
    "\n",
    "        # Treatment indicator and covariates\n",
    "        if len(varnames) == 1:  # 1 ~ D/X\n",
    "            if ignore_treat == 0:  # 1 ~ D\n",
    "                D = varnames[0]\n",
    "                X = None\n",
    "            else:  # 1 ~ X\n",
    "                raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "            if type in [\"missing\", \"miss\"]:  # 1 ~ variable, type(miss): not allowed\n",
    "                raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "        elif len(varnames) == 2:  # 1 ~ D + X\n",
    "            if ignore_treat == 0:  # 1 ~ D + X\n",
    "                D = varnames[0]\n",
    "                X = varnames[1]\n",
    "            else:  # 1 ~ X\n",
    "                raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "        else:  # len(varnames) > 2\n",
    "            if ignore_treat == 0:\n",
    "                D = varnames[0]\n",
    "                X = varnames[1:]\n",
    "            else:\n",
    "                raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "else:  # No formula provided\n",
    "    varnames = [Y, D, X]\n",
    "    if D is None and X is None:  # Y = \"Y\", set type = \"miss\" as default\n",
    "        if type == \"treat\":\n",
    "            print('\"type = treat\" not allowed. Plot \"type = missing\" instead.')\n",
    "            type = \"missing\"\n",
    "            \n",
    "    varnames = [var for var in varnames if var is not None]\n",
    "\n",
    "    \n",
    "\n",
    "# Check for incorrect variable names\n",
    "for var in varnames:\n",
    "    if var not in data.columns:\n",
    "        raise ValueError(f'Variable \"{var}\" is not in the dataset.')\n",
    "\n",
    "# Check index specification\n",
    "if len(index) != 2 or sum([i in data.columns for i in index]) != 2:\n",
    "    raise ValueError('\"index\" option misspecified. Try, for example, index = [\"unit.id\", \"time\"].')\n",
    "\n",
    "# Assign index names\n",
    "index_id = index[0]\n",
    "index_time = index[1]\n",
    "\n",
    "varV = None\n",
    "nv = None\n",
    "\n",
    "# Handle missing value report if needed\n",
    "if report_missing:\n",
    "    varV = [Y, D] + X if X is not None else [Y, D]\n",
    "    nv = len(varV)\n",
    "\n",
    "    # Create a matrix for missing values\n",
    "    missing_data = pd.DataFrame({\n",
    "        \"# Missing\": data[varV].isna().sum(),\n",
    "        \"% Missing\": round(data[varV].isna().mean() * 100, 1)\n",
    "    })\n",
    "\n",
    "    print(missing_data)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Set leave.gap logic\n",
    "if by_cohort:\n",
    "    leave_gap = 1\n",
    "\n",
    "# Handle missing data based on leave_gap\n",
    "if leave_gap == 0:\n",
    "    data = data.dropna()\n",
    "else:\n",
    "    # Create row-wise missing value counts\n",
    "    data['rowmiss'] = data.isna().sum(axis=1)\n",
    "    data['minrowmiss'] = data.groupby(index_id)['rowmiss'].transform('min')\n",
    "\n",
    "    # Drop units where all periods have missing values\n",
    "    data = data[data['minrowmiss'] == 0]\n",
    "    data = data.drop(columns=['rowmiss', 'minrowmiss'])\n",
    "\n",
    "\n",
    "# Sort the data by index\n",
    "data = data.sort_values(by=[index_id, index_time])\n",
    "\n",
    "# Calculate time gap\n",
    "min_time = data[index_time].min()\n",
    "max_time = data[index_time].max()\n",
    "unique_times = data[index_time].nunique()\n",
    "time_gap = (max_time - min_time) / (unique_times - 1)\n",
    "int_time_gap = int(time_gap)\n",
    "\n",
    "# Calculate difference in time between consecutive observations\n",
    "data['differencetime'] = data.groupby(index_id)[index_time].diff()\n",
    "min_time_gap = data['differencetime'].min()\n",
    "max_time_gap = data['differencetime'].max()\n",
    "\n",
    "# Check for time gaps\n",
    "if leave_gap == 0:\n",
    "    if time_gap != min_time_gap or time_gap != int_time_gap:\n",
    "        print(\"Time is not evenly distributed (possibly due to missing data).\\n\")\n",
    "\n",
    "# Handle leave_gap == 1 (expand panel data)\n",
    "if leave_gap == 1:\n",
    "    # Calculate time differences within each unit\n",
    "    data['differencetime'] = data.groupby(index_id)[index_time].diff()\n",
    "    min_time_gap = data['differencetime'].min()\n",
    "    max_time_gap = data['differencetime'].max()\n",
    "    divide_differencetime = max_time_gap / min_time_gap if min_time_gap != 0 else np.inf\n",
    "\n",
    "    if time_gap != min_time_gap or int_time_gap != time_gap:\n",
    "        if min_time_gap != max_time_gap and min_time_gap != 1 and divide_differencetime == int(divide_differencetime):\n",
    "            # Create all combinations of 'id' and 'time' based on the minimum time gap\n",
    "            g = pd.DataFrame({\n",
    "                index_id: np.repeat(data[index_id].unique(), len(np.arange(min_time, max_time + min_time_gap, min_time_gap))),\n",
    "                index_time: np.tile(np.arange(min_time, max_time + min_time_gap, min_time_gap), data[index_id].nunique())\n",
    "            })\n",
    "            # Merge g with the data\n",
    "            data = pd.merge(g, data, how='left', on=[index_id, index_time])\n",
    "        else:\n",
    "            g = pd.DataFrame({\n",
    "                index_id: np.repeat(data[index_id].unique(), len(np.arange(min_time, max_time + 1))),\n",
    "                index_time: np.tile(np.arange(min_time, max_time + 1), data[index_id].nunique())\n",
    "            })\n",
    "            data = pd.merge(g, data, how='left', on=[index_id, index_time])\n",
    "\n",
    "    data.drop(columns=['differencetime'], inplace=True)\n",
    "\n",
    "# Check for duplicated observations\n",
    "unique_label = data[index_id].astype(str) + \"_\" + data[index_time].astype(str)\n",
    "if unique_label.nunique() != len(data):\n",
    "    raise ValueError(\"Unit and time variables do not uniquely identify all observations. Some may be duplicated.\")\n",
    "\n",
    "# Limit units for gridOff\n",
    "if data[index_id].nunique() > 300 and not gridOff and type != \"outcome\":\n",
    "    print(\"Number of units is more than 300, setting 'gridOff = TRUE'.\")\n",
    "    gridOff = True\n",
    "\n",
    "if display_all == False and data[index_id].nunique() > 500:\n",
    "    print(\"Number of units is more than 500, randomly selecting 500 units for display.\")\n",
    "    sample_subject_ids = np.random.choice(data[index_id].unique(), 500, replace=False)\n",
    "    data = data[data[index_id].isin(sample_subject_ids)]\n",
    "\n",
    "##-------------------------------##\n",
    "## Checking Other Parameters\n",
    "##-------------------------------## \n",
    "\n",
    "\n",
    "# Check the 'type' option\n",
    "if type not in [\"miss\", \"missing\", \"raw\", \"treat\", \"outcome\", \"bivar\", \"bivariate\"]:\n",
    "    raise ValueError('\"type\" option misspecified.')\n",
    "\n",
    "# Adjust for \"missing\" or \"miss\" types\n",
    "if type in [\"missing\", \"miss\"]:\n",
    "    type = \"treat\"\n",
    "    ignore_treat = 1\n",
    "\n",
    "# Adjust for \"raw\" type\n",
    "if type == \"raw\":\n",
    "    type = \"outcome\"\n",
    "\n",
    "# Update cex settings based on group\n",
    "if by_group or type == \"outcome\":\n",
    "    cex_main_top = cex_main\n",
    "    cex_main = cex_main_sub\n",
    "\n",
    "# Handle axis labels\n",
    "if cex_axis_x is None:\n",
    "    cex_axis_x = cex_axis\n",
    "\n",
    "if cex_axis_y is None:\n",
    "    cex_axis_y = cex_axis\n",
    "\n",
    "# Check if treatment indicator is available\n",
    "if D is None and ignore_treat == 0:\n",
    "    print(\"No treatment indicator.\")\n",
    "    ignore_treat = 1\n",
    "\n",
    "# Check if outcomes are available for certain types\n",
    "if Y is None and type in [\"outcome\", \"bivar\", \"bivariate\"]:\n",
    "    raise ValueError(\"No outcomes.\")\n",
    "\n",
    "# Validate axis.lab option\n",
    "if axis_lab not in [\"both\", \"unit\", \"time\", \"off\"]:\n",
    "    raise ValueError('\"axis.lab\" option misspecified. Try, for example, axis.lab = [\"both\", \"unit\", \"time\", \"off\"].')\n",
    "\n",
    "# Validate axis.lab.gap\n",
    "if any(np.array(axis_lab_gap) < 0):\n",
    "    raise ValueError('\"axis.lab.gap\" should be greater than or equal to 0.')\n",
    "\n",
    "# Validate legend labels\n",
    "if legend_labs is not None:\n",
    "    legend_labs = [str(lab) for lab in legend_labs]\n",
    "\n",
    "# Validate outcome.type\n",
    "if outcome_type not in [\"continuous\", \"discrete\"]:\n",
    "    raise ValueError('\"outcome.type\" option misspecified. Try, for example, outcome_type = [\"continuous\", \"discrete\"].')\n",
    "\n",
    "# Handle treatment indicator checks\n",
    "d_levels = None\n",
    "d_bi = False\n",
    "\n",
    "# Without ignore.treat\n",
    "if ignore_treat == 0:\n",
    "    if leave_gap == 0:\n",
    "        if not pd.api.types.is_numeric_dtype(data[D]):\n",
    "            raise ValueError(\"Treatment indicator should be a numeric value.\")\n",
    "\n",
    "    d_levels = sorted(data[D].dropna().unique())\n",
    "    n_levels = len(d_levels)\n",
    "    d_bi = d_levels == [0, 1] and n_levels == 2  # Binary treatment check\n",
    "\n",
    "    if not d_bi and by_cohort:\n",
    "        raise ValueError('Option \"by.cohort = TRUE\" works only with dummy treatment variable')\n",
    "\n",
    "    if outcome_type == \"discrete\":\n",
    "        y_levels = sorted(data[Y].unique())\n",
    "\n",
    "    if n_levels == 1:\n",
    "        print(\"Only one treatment level...\")\n",
    "        ignore_treat = 1\n",
    "    else:\n",
    "        if not d_bi:\n",
    "            print(f\"{n_levels} treatment levels.\")\n",
    "\n",
    "    # Treatment type validation\n",
    "    if treat_type is not None:\n",
    "        if treat_type not in [\"discrete\", \"continuous\"]:\n",
    "            raise ValueError('\"treat.type\" must be \"discrete\" or \"continuous\".')\n",
    "\n",
    "        if treat_type == \"discrete\" and n_levels >= 5:\n",
    "            print(\"Too many treatment levels; treat as continuous.\")\n",
    "            treat_type = \"continuous\"\n",
    "\n",
    "        if treat_type == \"continuous\" and n_levels <= 4:\n",
    "            print(\"Too few treatment levels; consider setting treat_type = 'discrete'.\")\n",
    "    else:\n",
    "        treat_type = \"continuous\" if n_levels > 5 else \"discrete\"\n",
    "\n",
    "else:  # ignore_treat == 1\n",
    "    n_levels = 0\n",
    "    treat_type = \"discrete\"\n",
    "\n",
    "# Check shade.post type\n",
    "if not isinstance(shade_post, (bool, int)):\n",
    "    raise ValueError('Incorrect type for option \"shade.post\".')\n",
    "\n",
    "## ------------------------ ##\n",
    "## parsing data.            ##\n",
    "## ------------------------ ##\n",
    "\n",
    "# Parsing data\n",
    "raw_id = sorted(data[index_id].unique())\n",
    "raw_time = sorted(data[index_time].unique())\n",
    "N = len(raw_id)\n",
    "TT = len(raw_time)\n",
    "N\n",
    "\n",
    "# Handling input.id\n",
    "input_id = None\n",
    "if id is not None:\n",
    "    if show_id is not None:\n",
    "        print(\"Using specified id.\")\n",
    "    remove_id = np.setdiff1d(id, raw_id)\n",
    "    if len(remove_id) != 0:\n",
    "        print(f\"List of units removed from dataset: {remove_id}\")\n",
    "        input_id = np.intersect1d(sorted(id), raw_id)\n",
    "    else:\n",
    "        input_id = sorted(id)\n",
    "else:\n",
    "    if show_id is not None:\n",
    "        if len(show_id) > N:\n",
    "            raise ValueError(\"Length of 'show.id' should not be larger than total number of units.\")\n",
    "        if not isinstance(show_id[0], (int, float)):\n",
    "            raise ValueError(\"'show.id' option misspecified. Try, for example, show_id = range(1, 100).\")\n",
    "        if any(np.array(show_id) > N):\n",
    "            raise ValueError(\"Some specified units are not in the data.\")\n",
    "        if len(np.unique(show_id)) != len(show_id):\n",
    "            raise ValueError(\"Repeated values in 'show.id' option.\")\n",
    "        input_id = np.array(raw_id)[show_id].tolist()\n",
    "    else:\n",
    "        input_id = raw_id\n",
    "\n",
    "input_id[:4]\n",
    "\n",
    "# Store variable names\n",
    "data_old = data.copy()\n",
    "Yname = Y\n",
    "Dname = D\n",
    "\n",
    "# Check missing values\n",
    "data['rowmiss'] = data.isna().sum(axis=1)\n",
    "rowmissname = 'rowmiss'\n",
    "\n",
    "# Subset data if necessary\n",
    "if len(input_id) != len(raw_id):\n",
    "    data = data[data[index_id].isin(input_id)]\n",
    "    N = len(input_id)\n",
    "\n",
    "# Initialize variables\n",
    "Y, D, I, M = None, None, None, None\n",
    "\n",
    "# Handling leave.gap == 0 (Balanced Panel)\n",
    "if leave_gap == 0:\n",
    "    if len(data) != TT * N:  # Unbalanced panel\n",
    "        data[index_id] = pd.factorize(data[index_id])[0] + 1\n",
    "        data[index_time] = pd.factorize(data[index_time])[0] + 1\n",
    "\n",
    "        if Yname is not None:\n",
    "            Y = np.full((TT, N), np.nan)\n",
    "        I = np.zeros((TT, N))\n",
    "\n",
    "        if ignore_treat == 0:\n",
    "            D = np.zeros((TT, N))\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if Yname is not None:\n",
    "                row_idx = int( data.iloc[i][index_time] - 1 )\n",
    "                col_idx = int( data.iloc[i][index_id] - 1 )\n",
    "                val_replace = data.iloc[i][Yname]\n",
    "                Y[ row_idx, col_idx ] = val_replace\n",
    "\n",
    "            if ignore_treat == 0:\n",
    "                row_idx = int(data.iloc[i][index_time] - 1)\n",
    "                col_idx = int( data.iloc[i][index_id] - 1 )\n",
    "                val_replace = data.iloc[i][Dname]\n",
    "                D[ row_idx, col_idx ] = val_replace\n",
    "\n",
    "            row_idx = int( data.iloc[i][index_time] - 1 )\n",
    "            col_idx = int( data.iloc[i][index_id] - 1 )\n",
    "            I[ row_idx, col_idx ] = 1\n",
    "\n",
    "    else:  # Balanced panel\n",
    "        I = np.ones((TT, N))\n",
    "        if Yname is not None:\n",
    "            Y = data[Yname].values.reshape((TT, N), order='F')\n",
    "        if ignore_treat == 0:\n",
    "            D = data[Dname].values.reshape((TT, N), order='F')\n",
    "\n",
    "else:  # leave.gap == 1 (Balanced panel with missing data)\n",
    "    data[index_id] = pd.factorize(data[index_id])[0] + 1\n",
    "    data[index_time] = pd.factorize(data[index_time])[0] + 1\n",
    "\n",
    "    M = np.zeros((TT, N))\n",
    "    for i in range(len(data)):\n",
    "        time_val = int(data.iloc[i][index_time] - 1)\n",
    "        unit_val = int( data.iloc[i][index_id] - 1 )\n",
    "        val_gap = data.iloc[i][rowmissname]\n",
    "        M[ time_val, unit_val ] = val_gap\n",
    "\n",
    "    if Yname is not None:\n",
    "        Y = np.full((TT, N), np.nan)\n",
    "    I = np.zeros((TT, N))\n",
    "    if ignore_treat == 0:\n",
    "        D = np.zeros((TT, N))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if Yname is not None:\n",
    "            row_idx = int( data.iloc[i][index_time] - 1 )\n",
    "            col_idx = int( data.iloc[i][index_id] - 1 )\n",
    "            val_gap = data.iloc[i][Yname]\n",
    "            Y[ row_idx, col_idx ] = val_gap\n",
    "\n",
    "        if ignore_treat == 0:\n",
    "            \n",
    "            row_idx = int( data.iloc[i][index_time] - 1 )\n",
    "            col_idx = int( data.iloc[i][index_id] - 1 )\n",
    "            val_gap = data.iloc[i][Dname]\n",
    "            D[ row_idx, col_idx ] = val_gap\n",
    "\n",
    "        row_idx = int( data.iloc[i][index_time] - 1 )\n",
    "        col_idx = int( data.iloc[i][index_id] - 1 )\n",
    "        I[ row_idx, col_idx ] = 1\n",
    "\n",
    "# Handling collapse.history == TRUE\n",
    "if collapse_history:\n",
    "    D_f = np.vstack([D, I]) if M is None else np.vstack([D, I, M])\n",
    "\n",
    "    D_d = pd.DataFrame(D_f.T)\n",
    "    ff = D_d.groupby(list(D_d.columns)).size().reset_index(name='COUNT')\n",
    "\n",
    "    D = ff.iloc[:, :TT].T.values\n",
    "    I = ff.iloc[:, TT:2 * TT].T.values\n",
    "\n",
    "    if M is None:\n",
    "        input_id = ff.iloc[:, 2 * TT].values\n",
    "    else:\n",
    "        M = ff.iloc[:, 2 * TT:3 * TT].T.values\n",
    "        input_id = ff.iloc[:, 3 * TT].values\n",
    "\n",
    "    N = len(input_id)\n",
    "\n",
    "    # Sort by cohort size\n",
    "    D_id = np.column_stack((np.arange(1, N + 1), input_id))\n",
    "    D_id = D_id[D_id[:, 1].argsort()[::-1]]\n",
    "    D_id_vec = D_id[:, 0].astype(int) - 1\n",
    "\n",
    "    input_id = D_id[:, 1]\n",
    "    D = D[:, D_id_vec]\n",
    "    I = I[:, D_id_vec]\n",
    "    if M is not None:\n",
    "        M = M[:, D_id_vec]\n",
    "\n",
    "if D is None:\n",
    "    D_old = None\n",
    "else:\n",
    "    D_old = D.copy()\n",
    "\n",
    "# Binary treatment indicator\n",
    "if not ignore_treat and d_bi:\n",
    "    if len(np.unique(D_old)) > 2:\n",
    "        D[D > 1] = 1\n",
    "\n",
    "    # Once treated, always treated\n",
    "    D = np.apply_along_axis(lambda x: np.cumsum(np.nan_to_num(x)) + (x == 0).astype(int) * 0, axis=0, arr=D)\n",
    "    co_total_all = TT - D.sum(axis=0)\n",
    "    D = (D > 0).astype(int)\n",
    "\n",
    "    tr_pos = np.where(D[TT - 1] == 1)[0]\n",
    "    T0 = np.sum(D == 0, axis=0)[tr_pos] + 1\n",
    "    T1 = np.sum(D == 1, axis=0)[tr_pos]\n",
    "\n",
    "    T1[T1 > 1] = 0\n",
    "    co_total = co_total_all[tr_pos]\n",
    "    DID = len(np.unique(T0)) == 1\n",
    "\n",
    "    if np.sum(np.abs(D_old[I == 1] - D[I == 1])) == 0:\n",
    "        staggered = 1\n",
    "    else:\n",
    "        DID = 0\n",
    "        staggered = 0\n",
    "else:\n",
    "    DID = 0\n",
    "    staggered = 1\n",
    "\n",
    "########################################\n",
    "## unified labels:\n",
    "##  -200 for missing\n",
    "##  -1 for control condition (or observed)\n",
    "##   0 for treated pre\n",
    "##   1 for treated post  \n",
    "########################################\n",
    "\n",
    "\n",
    "obs_missing = None\n",
    "if leave_gap == 0:\n",
    "    if ignore_treat == 0 and d_bi == 1:  # binary, and without ignore_treat\n",
    "        con1 = type == \"treat\" and pre_post is True\n",
    "        con2 = type == \"outcome\" and by_group is False\n",
    "\n",
    "        if staggered == 1 and (con1 or con2):  # DID type data\n",
    "            tr = D[(TT-1), :] == 1  # cross-sectional: treated unit\n",
    "\n",
    "            id_tr = np.where(tr == 1)[0]\n",
    "            id_co = np.where(tr == 0)[0]\n",
    "\n",
    "            D_tr = D[:, id_tr]\n",
    "            I_tr = I[:, id_tr]\n",
    "            Y_tr = Y_co = None\n",
    "            if type == \"outcome\":\n",
    "                Y_tr = Y[:, id_tr]\n",
    "                Y_co = Y[:, id_co]\n",
    "\n",
    "            Ntr = np.sum(tr)\n",
    "            Nco = N - Ntr\n",
    "\n",
    "            # 1. control group: -1\n",
    "            obs_missing = np.full((TT, N), -1)\n",
    "            # 2. add treated units\n",
    "            obs_missing[:, id_tr] = D[:, id_tr]\n",
    "            # 3. set missing values\n",
    "            obs_missing[np.where(I == 0)] = -200  # missing -200; I==0: missings in unbalanced panel\n",
    "\n",
    "            unit_type = np.full(N, 1)  # 1 for control; 2 for treated; 3 for reversal\n",
    "            unit_type[id_tr] = 2\n",
    "\n",
    "        else:\n",
    "            unit_type = np.full(N, np.nan)  # 1 for control; 2 for treated; 3 for reversal\n",
    "\n",
    "            for i in range(N):\n",
    "                di = D_old[:, i]\n",
    "                ii = I[:, i]\n",
    "\n",
    "                if len(np.unique(di[np.where(ii == 1)])) == 1:  # treated or control\n",
    "                    if 0 in np.unique(di[np.where(ii == 1)]):\n",
    "                        unit_type[i] = 1  # always control\n",
    "                    else:\n",
    "                        unit_type[i] = 2  # always treated\n",
    "                else:\n",
    "                    unit_type[i] = 3  # control to treated / treated to control\n",
    "\n",
    "            # 1. using D_old  \n",
    "            obs_missing = D_old.copy()\n",
    "            # 2. set controls\n",
    "            obs_missing[np.where(D_old == 0)] = -1  # under control\n",
    "            # 3. set missing \n",
    "            obs_missing[np.where(I == 0)] = -200  # missing\n",
    "\n",
    "        obs_missing_treat = obs_missing.copy()\n",
    "        if len(np.unique(D_old)) > 2:\n",
    "            obs_missing[np.where(obs_missing > 1)] = 1\n",
    "\n",
    "    else:  # either not binary (>2 treatment levels) or ignore_treat == 1\n",
    "        if n_levels > 2 and type == \"treat\":  # >2 treatment levels\n",
    "            obs_missing = D.copy()\n",
    "            obs_missing[np.where(I == 0)] = np.nan\n",
    "        else:\n",
    "            obs_missing = np.full((TT, N), -1)\n",
    "            obs_missing[np.where(I == 0)] = -200  # missing\n",
    "            ignore_treat = 1\n",
    "\n",
    "elif leave_gap == 1:\n",
    "    if ignore_treat == 0 and d_bi == 1:  # binary, and without ignore_treat\n",
    "        con1 = type == \"treat\" and pre_post is True\n",
    "        con2 = type == \"outcome\" and by_group is False\n",
    "\n",
    "        if staggered == 1 and (con1 or con2):  # DID type data\n",
    "            tr = D[TT, :] == 1  # cross-sectional: treated unit\n",
    "\n",
    "            id_tr = np.where(tr == 1)[0]\n",
    "            id_co = np.where(tr == 0)[0]\n",
    "\n",
    "            D_tr = D[:, id_tr]\n",
    "            I_tr = I[:, id_tr]\n",
    "            Y_tr = Y_co = None\n",
    "\n",
    "            if type == \"outcome\":\n",
    "                Y_tr = Y[:, id_tr]\n",
    "                Y_co = Y[:, id_co]\n",
    "\n",
    "            Ntr = np.sum(tr)\n",
    "            Nco = N - Ntr\n",
    "\n",
    "            # 1. control group: -1\n",
    "            obs_missing = np.full((TT, N), -1)\n",
    "            # 2. add treated units\n",
    "            obs_missing[:, id_tr] = D[:, id_tr]\n",
    "            # 3. set missing values\n",
    "            obs_missing[np.where(I == 0)] = -200  # missing -200\n",
    "            obs_missing[np.where(M != 0)] = -200\n",
    "\n",
    "            unit_type = np.full(N, 1)  # 1 for control; 2 for treated; 3 for reversal\n",
    "            unit_type[id_tr] = 2\n",
    "\n",
    "        else:\n",
    "            unit_type = np.full(N, np.nan)  # 1 for control; 2 for treated; 3 for reversal\n",
    "\n",
    "            for i in range(N):\n",
    "                di = D_old[:, i]\n",
    "                ii = I[:, i]  # I: observed or missing\n",
    "\n",
    "                if len(np.unique(di[np.where(ii == 1)])) == 1:  # treated or control\n",
    "                    if 0 in np.unique(di[np.where(ii == 1)]):\n",
    "                        unit_type[i] = 1  # control\n",
    "                    else:\n",
    "                        unit_type[i] = 2  # treated\n",
    "                elif len(np.unique(di[np.where(ii == 1)])) == 2 and np.nan in np.unique(di[np.where(ii == 1)]):\n",
    "                    if 0 in np.unique(di[np.where(ii == 1)]):\n",
    "                        unit_type[i] = 1  # control\n",
    "                    else:\n",
    "                        unit_type[i] = 2  # treated\n",
    "                else:\n",
    "                    unit_type[i] = 3  # control to treated / treated to control / NA 0 1 / NA 1 0\n",
    "\n",
    "            # 1. using D_old  \n",
    "            obs_missing = D_old.copy()\n",
    "            # 2. set controls\n",
    "            obs_missing[np.where(D_old == 0)] = -1  # under control\n",
    "            # 3. set missing \n",
    "            obs_missing[np.where(I == 0)] = -200  # missing\n",
    "            obs_missing[np.where(M != 0)] = -200\n",
    "\n",
    "        obs_missing_treat = obs_missing.copy()\n",
    "        if len(np.unique(D_old)) > 2:\n",
    "            obs_missing[np.where(obs_missing > 1)] = 1\n",
    "\n",
    "    else:  # either not binary (>2 treatment levels) or ignore_treat == 1\n",
    "        if n_levels > 2 and type == \"treat\":  # >2 treatment levels\n",
    "            obs_missing = D.copy()\n",
    "            obs_missing[np.where(I == 0)] = -200\n",
    "            obs_missing[np.where(M != 0)] = -200\n",
    "        else:\n",
    "            obs_missing = np.full((TT, N), -1)\n",
    "            obs_missing[np.where(I == 0)] = -200\n",
    "            obs_missing[np.where(M != 0)] = -200\n",
    "            ignore_treat = 1\n",
    "\n",
    "# Setting column and row names\n",
    "obs_missing = pd.DataFrame(obs_missing, columns=input_id, index=raw_time)\n",
    "\n",
    "# Setting time and id for the final output\n",
    "time = raw_time\n",
    "id = input_id\n",
    "\n",
    "# Check if xlim is valid\n",
    "if xlim is not None:\n",
    "    if not isinstance(xlim, list) or not all(isinstance(i, (int, float)) for i in xlim):\n",
    "        raise ValueError('Some element in \"xlim\" is not numeric.')\n",
    "    elif len(xlim) != 2:\n",
    "        raise ValueError('\"xlim\" must be of length 2.')\n",
    "\n",
    "# Check if ylim is valid\n",
    "if type not in [\"bivar\", \"bivariate\"]:\n",
    "    if ylim is not None:\n",
    "        if not isinstance(ylim, list) or not all(isinstance(i, (int, float)) for i in ylim):\n",
    "            raise ValueError('Some element in \"ylim\" is not numeric.')\n",
    "        elif len(ylim) != 2:\n",
    "            raise ValueError('\"ylim\" must be of length 2.')\n",
    "\n",
    "# Check if xlab is valid\n",
    "if xlab is not None:\n",
    "    if not isinstance(xlab, str):\n",
    "        raise ValueError('\"xlab\" is not a string.')\n",
    "    else:\n",
    "        xlab = xlab\n",
    "\n",
    "# Check if ylab is valid\n",
    "if ylab is not None:\n",
    "    if not isinstance(ylab, str):\n",
    "        raise ValueError('\"ylab\" is not a string.')\n",
    "    else:\n",
    "        ylab = ylab\n",
    "\n",
    "# Check if legendOff is a valid logical flag\n",
    "if not isinstance(legendOff, (bool, int)):\n",
    "    raise ValueError('\"legendOff\" is not a logical flag.')\n",
    "\n",
    "# Check if gridOff is a valid logical flag\n",
    "if not isinstance(gridOff, (bool, int)):\n",
    "    raise ValueError('\"gridOff\" is not a logical flag.')\n",
    "\n",
    "# Check if main is valid\n",
    "if main is not None:\n",
    "    if not isinstance(main, str):\n",
    "        raise ValueError('\"main\" is not a string.')\n",
    "    else:\n",
    "        main = main\n",
    "\n",
    "# Handle axis.lab.angle\n",
    "if axis_lab_angle is not None:\n",
    "    angle = axis_lab_angle\n",
    "    x_v, x_h = 1, 1\n",
    "else:\n",
    "    if axis_adjust:\n",
    "        angle = 45\n",
    "        x_v, x_h = 1, 1\n",
    "    else:\n",
    "        angle = 0\n",
    "        x_v = 0\n",
    "        if type == \"treat\":\n",
    "            x_h = 0.5\n",
    "        else:\n",
    "            x_h = 0\n",
    "\n",
    "# Type of plots\n",
    "if not isinstance(time[0], (int, float)):\n",
    "    time = list(range(1, TT + 1))\n",
    "\n",
    "# Periods to show\n",
    "if xlim:\n",
    "    show = [i for i, t in enumerate(time) if xlim[0] <= t <= xlim[1]]\n",
    "else:\n",
    "    show = list(range(len(time)))\n",
    "\n",
    "nT = len(show)\n",
    "time_label = [raw_time[i] for i in show]\n",
    "T_b = list(range(1, len(show) + 1))\n",
    "\n",
    "# Labels\n",
    "N_b = list(range(1, N + 1))\n",
    "if type == \"treat\":\n",
    "    if axis_lab == \"both\":\n",
    "        if len(axis_lab_gap) == 2:\n",
    "            x_gap, y_gap = axis_lab_gap\n",
    "        else:\n",
    "            x_gap = y_gap = axis_lab_gap[0]\n",
    "    else:\n",
    "        x_gap = y_gap = axis_lab_gap[0]\n",
    "    \n",
    "    if y_gap != 0:\n",
    "        N_b = list(range(N, 0, -(y_gap + 1)))\n",
    "else:\n",
    "    x_gap = axis_lab_gap[0]\n",
    "\n",
    "if x_gap != 0:\n",
    "    T_b = list(range(1, len(show) + 1, x_gap + 1))\n",
    "\n",
    "# Legend on/off\n",
    "legend_pos = \"none\" if legendOff else \"bottom\"\n",
    "\n",
    "# # Output for debugging (optional)\n",
    "# print(f\"xlab: {xlab}, ylab: {ylab}, main: {main}\")\n",
    "# print(f\"Legend Position: {legend_pos}\")\n",
    "# print(f\"Show time periods: {show}\")\n",
    "# print(f\"Angle: {angle}, x_v: {x_v}, x_h: {x_h}\")\n",
    "\n",
    "\n",
    "# if treat == 'treat':f\n",
    "\n",
    "# Conditional logic for labels and title\n",
    "if xlab is None:\n",
    "    xlab = index[1]\n",
    "elif xlab == \"\":\n",
    "    xlab = None\n",
    "\n",
    "if ylab is None:\n",
    "    ylab = index[0]\n",
    "    if collapse_history:\n",
    "        ylab = \"Number of Units\"\n",
    "elif ylab == \"\":\n",
    "    ylab = None\n",
    "\n",
    "if main is None:\n",
    "    if collapse_history:\n",
    "        main = \"Unique Treatment Histories\"\n",
    "    else:\n",
    "        main = \"Treatment Status\" if ignore_treat == 0 else \"Missing Values\"\n",
    "elif main == \"\":\n",
    "    main = None\n",
    "\n",
    "# Generate units and periods\n",
    "units = np.repeat(np.arange(N, 0, -1), TT)\n",
    "period = np.tile(np.arange(1, TT + 1), N)\n",
    "\n",
    "# Extract the selected rows and convert to a NumPy array (if not already)\n",
    "m = np.array(obs_missing.iloc[show, :])\n",
    "\n",
    "# Flatten the array, remove NaN values, and find the unique values\n",
    "all_values = np.unique(m[~np.isnan(m)])\n",
    "\n",
    "\n",
    "col = []\n",
    "label = []\n",
    "breaks = []\n",
    "# Setting col and labels based on treatment type and level\n",
    "if ((not d_bi) and (ignore_treat == 0)):  # More than 2 treatment levels\n",
    "\n",
    "    tr_col = [\"#66C2A5\", \"#FC8D62\", \"#8DA0CB\", \"#E78AC3\", \"#A6D854\", \"#FFD92F\"]\n",
    "    \n",
    "    if treat_type == \"discrete\":\n",
    "        for i in range(n_levels):\n",
    "            breaks.append(d_levels[i])\n",
    "            # label.append(f\"Treatment level: {d_levels[i]}\")  # If you want to include \"Treatment level\"\n",
    "            label.append(f\"{d_levels[i]}\")\n",
    "        col = tr_col[:n_levels]\n",
    "    else:\n",
    "        print(\"Continuous treatment.\")\n",
    "        interval = (max(all_values) - min(all_values)) / 4\n",
    "        for i in range(5):\n",
    "            breaks.append(min(all_values) + i * interval)\n",
    "        col = [\"#c6dbef\", \"#4292c6\", \"#1f78b4\", \"#08519c\", \"#042b53\"]\n",
    "\n",
    "    if -200 in all_values:\n",
    "        col.append(\"#FFFFFF\")\n",
    "        breaks.append(-200)\n",
    "        label.append(\"Missing\")\n",
    "else:  # Binary treatment indicator\n",
    "    if (0 in all_values):  # General DID type data\n",
    "        \n",
    "        \n",
    "        if -1 in all_values:\n",
    "            col.append(\"#B0C4DE\")\n",
    "            breaks.append(-1)\n",
    "            label.append(\"Controls\")\n",
    "        \n",
    "        col.append(\"#4671D5\")\n",
    "        breaks.append(0)\n",
    "        label.append(\"Treated (Pre)\")\n",
    "\n",
    "        if 1 in all_values:\n",
    "            col.append(\"#06266F\")\n",
    "            breaks.append(1)\n",
    "            label.append(\"Treated (Post)\")\n",
    "            \n",
    "    else:\n",
    "    \n",
    "        # Control condition\n",
    "        if -1 in all_values:\n",
    "            col.append(\"#B0C4DE\")\n",
    "            breaks.append(-1)\n",
    "            if ignore_treat == 0:\n",
    "                # Assuming pre_post is not used, so directly appending \"Under Control\"\n",
    "                label.append(\"Under Control\")\n",
    "            else:\n",
    "                label.append(\"Observed\")\n",
    "\n",
    "        # Treated condition\n",
    "        if 1 in all_values:\n",
    "            col.append(\"#06266F\")\n",
    "            breaks.append(1)\n",
    "            # Assuming pre_post is not used, so directly appending \"Under Treatment\"\n",
    "            label.append(\"Under Treatment\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    # Additional missing value handling\n",
    "    if -200 in all_values:\n",
    "        col.append(\"#FFFFFF\")\n",
    "        breaks.append(-200)\n",
    "        label.append(\"Missing\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    # If the condition is met, execute the following:\n",
    "    if len(id) > 1 and ignore_treat == 0 and d_bi:\n",
    "\n",
    "        if by_timing:\n",
    "            # Get indices for control units (unit_type == 1)\n",
    "            co_seq = np.where(unit_type == 1)[0]\n",
    "            # Get indices for treated units (not control)\n",
    "            tr_seq = np.setdiff1d(np.arange(N), co_seq)\n",
    "\n",
    "            # Create a DataFrame similar to cbind in R\n",
    "            dataT0 = pd.DataFrame({\n",
    "                'id': tr_seq,\n",
    "                'T0': T0,\n",
    "                'co_total': co_total\n",
    "            })\n",
    "\n",
    "            # Sort by T0, co_total, and id\n",
    "            dataT0 = dataT0.sort_values(by=['T0', 'co_total', 'id'])\n",
    "\n",
    "            # Extract the sorted ids\n",
    "            tr_seq = dataT0['id'].values\n",
    "            missing_seq = np.concatenate((tr_seq, co_seq))\n",
    "\n",
    "            # Reorder the matrix 'm' and 'id'\n",
    "            m = m[:, missing_seq]\n",
    "            id = np.array(id)[missing_seq]\n",
    "\n",
    "\n",
    "# User-defined color setting\n",
    "if color is not None:\n",
    "    if treat_type == \"discrete\":  # Discrete treatment indicator\n",
    "        if len(col) == len(color):\n",
    "            print(f\"Specified col in the order of: {', '.join(label)}.\")\n",
    "            col = color\n",
    "        else:\n",
    "            raise ValueError(f\"Length of 'color' should be equal to {len(col)}.\")\n",
    "\n",
    "# User-defined legend labels\n",
    "if legend_labs is not None:\n",
    "    if treat_type == \"discrete\":  # Discrete treatment indicator\n",
    "        if len(legend_labs) != len(label):\n",
    "            print(\"Warning: Incorrect number of labels in the legends. Using default.\")\n",
    "        else:\n",
    "            print(f\"Specified labels in the order of: {', '.join(legend_labs)}.\")\n",
    "            label = legend_labs\n",
    "\n",
    "\n",
    "# Create the data frame for plotting\n",
    "data = pd.DataFrame({\n",
    "    'units': units,\n",
    "    'period': period,\n",
    "    'res': m.T[::-1, :].ravel()\n",
    "})\n",
    "\n",
    "# Remove NA values if leave.gap is 0 (adjust according to your logic)\n",
    "leave_gap = 0\n",
    "if leave_gap == 0:\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "# id = list( reversed( id ) )  # Reverse ID list\n",
    "\n",
    "# Check if N >= 200\n",
    "if m.shape[1] >= 200:\n",
    "    if axis_lab == \"both\":\n",
    "        axis_lab = \"time\"\n",
    "    elif axis_lab == \"unit\":\n",
    "        axis_lab = \"off\"\n",
    "\n",
    "# Set background color\n",
    "if background is not None:\n",
    "    grid_color = border_color = background_color = legend_color = background\n",
    "else:\n",
    "    grid_color = border_color = background_color = legend_color = \"#E5E5E5\"\n",
    "\n",
    "\n",
    "# Plot with seaborn/matplotlib\n",
    "if ((by_timing == True) and ( pre_post == False ) ):\n",
    "    print('by timing')\n",
    "    data2plot = data.pivot(index='units', columns='period', values='res')\n",
    "\n",
    "    # Reverse the id values\n",
    "#     id = id[::-1]\n",
    "elif pre_post == True:\n",
    "    data2plot = data.pivot(index='units', columns='period', values='res') \\\n",
    "                    .sort_values(['units'], ascending = True)\n",
    "    print('jola')\n",
    "#     id = id[::-1]\n",
    "else:\n",
    "    data2plot = data.pivot(index='units', columns='period', values='res')\n",
    "    \n",
    "\n",
    "# Manually setting grid and background col\n",
    "if not gridOff:\n",
    "    plt.figure(figsize=(12, 8), facecolor = grid_color)\n",
    "    \n",
    "else:\n",
    "    plt.figure(figsize=(12, 8), facecolor = 'white')\n",
    "\n",
    "    \n",
    "# Generating the colors\n",
    "dict_cols = dict(zip(breaks, col))\n",
    "keys_sorted = sorted( dict_cols )\n",
    "col_sorted = []\n",
    "for key in keys_sorted:\n",
    "    col_sorted.append(dict_cols[key])\n",
    "cmap = ListedColormap(col_sorted)\n",
    "\n",
    "# Generating the breaks\n",
    "breaks_sort = np.sort(np.array([ min(breaks) - 1 ] + breaks) + 0.5)\n",
    "norm = BoundaryNorm(boundaries=breaks_sort, ncolors=len(col_sorted))\n",
    "\n",
    "sns.heatmap( data2plot, cmap=cmap, norm=norm,\n",
    "            cbar=False, \n",
    "           linewidths=0.5, linecolor='#eef2f9')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(f'{xlab}' if axis_lab in [\"both\", \"time\"] else \"Time\")\n",
    "plt.ylabel(f'{ylab}' if axis_lab in [\"both\", \"unit\"] else \"Unit\")\n",
    "plt.title(f'{main}', fontsize = cex_main)\n",
    "\n",
    "\n",
    "\n",
    "# Adjusting legend\n",
    "if n_levels < 3:\n",
    "    control_patch = mpatches.Patch(color=col[0], label=label[0])\n",
    "    treatme_patch = mpatches.Patch(color=col[1], label=label[1])\n",
    "    plt.legend(handles=[ control_patch, treatme_patch ], title=\"\", frameon=False, \n",
    "               loc='lower center',  bbox_to_anchor=(0.5, -0.15), ncol=2 )\n",
    "    \n",
    "if n_levels == 3:\n",
    "    control_patch = mpatches.Patch(color=col[0], label=label[0])\n",
    "    treatme_patch = mpatches.Patch(color=col[1], label=label[1])\n",
    "    new_treatme_patch = mpatches.Patch(color=col[2], label=label[2])\n",
    "    plt.legend(handles=[ control_patch, treatme_patch, new_treatme_patch ], \n",
    "               title=\"Treatment level:\", frameon=False, \n",
    "               loc='lower center',  bbox_to_anchor=(0.5, -0.15), ncol=3 )\n",
    "\n",
    "\n",
    "\n",
    "# Customizing the x and y axis based on the condition\n",
    "if axis_lab == \"both\":\n",
    "    plt.xticks(ticks= np.array(T_b) - 0.5 , labels=[time_label[b-1] for b in T_b], \n",
    "               rotation=angle, ha='center', fontsize= cex_axis_x )\n",
    "    plt.yticks(ticks= np.array(N_b) - 0.5 , labels=[id[ b-1 ] for b in N_b],rotation=0, \n",
    "               fontsize= cex_axis_y)\n",
    "\n",
    "elif axis_lab == \"unit\":\n",
    "    plt.xticks(ticks= np.array(T_b) - 0.5, labels=None, fontsize= cex_axis_x)\n",
    "    plt.yticks(ticks= np.array(N_b) - 0.5 , labels=[id[ b-1 ] for b in N_b], rotation=0,\n",
    "               fontsize= cex_axis_y)\n",
    "    \n",
    "elif axis_lab == \"time\":\n",
    "    plt.xticks(ticks= np.array(T_b) - 0.5 , labels=[time_label[b-1] for b in T_b], \n",
    "               rotation=angle, ha='center', fontsize= cex_axis_x )\n",
    "    plt.yticks(ticks= [] , rotation=0 )\n",
    "    \n",
    "elif axis_lab == \"off\":\n",
    "    plt.xticks(ticks=[], labels=[], rotation=0)\n",
    "    plt.yticks(ticks=[], labels=[], rotation=0)\n",
    "\n",
    "# Setting legend\n",
    "if ((len(breaks) >= 4) and (len(breaks) < 6)):\n",
    "    plt.legend(ncol=2, loc='lower center')\n",
    "\n",
    "# plt.ylim(0, 0)\n",
    "# Display the plot\n",
    "# Hide x and y axis tick lines\n",
    "plt.tick_params(axis='x', which='both', length=0)  # Hide x-axis ticks\n",
    "plt.tick_params(axis='y', which='both', length=0)  # Hide y-axis ticks\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253b1a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e182549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to DataFrame if needed\n",
    "# if not isinstance(data, pd.DataFrame):\n",
    "#     data = pd.DataFrame(data)\n",
    "\n",
    "# # Convert index to string or numeric depending on the content\n",
    "# if pd.api.types.is_categorical_dtype(data[index[0]]):\n",
    "#     if pd.to_numeric(data[index[0]], errors='coerce').isna().sum() > 0:  # Contains text\n",
    "#         data[index[0]] = data[index[0]].astype(str)\n",
    "#     else:  # Contains numbers\n",
    "#         data[index[0]] = pd.to_numeric(data[index[0]].cat.codes, errors='coerce')\n",
    "\n",
    "# # Number of unique units\n",
    "# N0 = data[index[0]].nunique()\n",
    "\n",
    "# if N0 <= 500:\n",
    "#     if collapse_history is None:\n",
    "#         collapse_history = False\n",
    "#     else:\n",
    "#         collapse_history = collapse_history\n",
    "\n",
    "#     if display_all is None:\n",
    "#         display_all = False\n",
    "#     else:\n",
    "#         display_all = display_all\n",
    "# else:\n",
    "#     if collapse_history is not None:\n",
    "#         if display_all is None:\n",
    "#             display_all = False\n",
    "#         else:\n",
    "#             display_all = display_all\n",
    "#     else:\n",
    "#         if display_all is None:\n",
    "#             if type != \"outcome\":\n",
    "#                 collapse_history = True\n",
    "#                 display_all = False\n",
    "#             else:\n",
    "#                 collapse_history = False\n",
    "#                 display_all = False\n",
    "#         else:\n",
    "#             collapse_history = False\n",
    "\n",
    "\n",
    "\n",
    "# # Check if 'leave_gap' is logical or in [0, 1]\n",
    "# if not isinstance(leave_gap, bool) and leave_gap not in [0, 1]:\n",
    "#     raise ValueError('\"leave_gap\" is not a logical flag.')\n",
    "\n",
    "# # Check if 'by_cohort' is logical or in [0, 1]\n",
    "# if not isinstance(by_cohort, bool) and by_cohort not in [0, 1]:\n",
    "#     raise ValueError('\"by_cohort\" is not a logical flag.')\n",
    "\n",
    "# # Check if 'display_all' is logical or in [0, 1]\n",
    "# if not isinstance(display_all, bool) and display_all not in [0, 1]:\n",
    "#     raise ValueError('\"display_all\" is not a logical flag.')\n",
    "\n",
    "# # Check if 'by_group_side' is logical or in [0, 1]\n",
    "# if not isinstance(by_group_side, bool) and by_group_side not in [0, 1]:\n",
    "#     raise ValueError('\"by_group_side\" is not a logical flag.')\n",
    "\n",
    "# # Check if 'by_unit' is logical or in [0, 1]\n",
    "# if not isinstance(by_unit, bool) and by_unit not in [0, 1]:\n",
    "#     raise ValueError('\"by_unit\" is not a logical flag.')\n",
    "\n",
    "# # Check if 'axis_adjust' is logical or in [0, 1]\n",
    "# if not isinstance(axis_adjust, bool) and axis_adjust not in [0, 1]:\n",
    "#     raise ValueError('\"axis_adjust\" is not a logical flag.')\n",
    "\n",
    "# # Check if 'axis_lab_angle' is numeric and within [0, 90]\n",
    "# if axis_lab_angle is not None:\n",
    "#     if not isinstance(axis_lab_angle, (int, float)):\n",
    "#         raise ValueError('\"axis_lab_angle\" must be numeric.')\n",
    "#     elif axis_lab_angle < 0 or axis_lab_angle > 90:\n",
    "#         raise ValueError('\"axis_lab_angle\" needs to be in [0, 90].')\n",
    "\n",
    "\n",
    "\n",
    "# # pre_post\n",
    "# if pre_post is None:\n",
    "#     if type == \"outcome\":\n",
    "#         pre_post = True\n",
    "#     else:\n",
    "#         pre_post = False\n",
    "\n",
    "# if not isinstance(pre_post, bool) and pre_post not in [0, 1]:\n",
    "#     raise ValueError('\"pre_post\" is not a logical flag.')\n",
    "\n",
    "# # theme_bw\n",
    "# if not isinstance(theme_bw, bool) and theme_bw not in [0, 1]:\n",
    "#     raise ValueError('\"theme_bw\" is not a logical flag.')\n",
    "\n",
    "# # by_timing\n",
    "# if not isinstance(by_timing, bool) and by_timing not in [0, 1]:\n",
    "#     raise ValueError('\"by_timing\" is not a logical flag.')\n",
    "\n",
    "# # by_group\n",
    "# if not isinstance(by_group, bool) and by_group not in [0, 1]:\n",
    "#     raise ValueError('\"by_group\" is not a logical flag.')\n",
    "\n",
    "# # ignore_treat\n",
    "# if not isinstance(ignore_treat, bool) and ignore_treat not in [0, 1]:\n",
    "#     raise ValueError('\"ignore_treat\" is not a logical flag.')\n",
    "\n",
    "# # Ensure that 'by_group_side' implies 'by_group'\n",
    "# if by_group_side:\n",
    "#     if not by_group:\n",
    "#         by_group = True\n",
    "\n",
    "# # Warning for 'by_group' and 'by_cohort' combination\n",
    "# if by_group:\n",
    "#     if by_cohort is not None:\n",
    "#         print('Warning: \"by_cohort\" is not allowed with \"by_group = True\" or \"by_group_side = True\". Ignored.')\n",
    "#         by_cohort = None  # Ignoring 'by_cohort'\n",
    "\n",
    "# # Handle 'type = missing' and 'ignore_treat'\n",
    "# if type in [\"missing\", \"miss\"]:\n",
    "#     if ignore_treat:\n",
    "#         raise ValueError('Option \"type = missing\" should not be combined with \"ignore_treat = True\".')\n",
    "\n",
    "# # Check combination of 'by_cohort' and 'type'\n",
    "# if type != \"outcome\" and by_cohort:\n",
    "#     raise ValueError('Option \"by_cohort = True\" should be combined with \"type = \\'outcome\\'\".')\n",
    "\n",
    "# # Check combination of 'type = outcome' and 'collapse_history'\n",
    "# if type == \"outcome\" and collapse_history:\n",
    "#     raise ValueError('Option \"collapse_history = True\" should not be combined with \"type = \\'outcome\\'\".')\n",
    "\n",
    "# # Handling the formula logic\n",
    "# if formula is not None:  # with formula\n",
    "\n",
    "#     # Check if the formula starts with \"~\"\n",
    "#     if formula.split(\"~\")[0] == \"\":\n",
    "#         raise ValueError('You need to specify \"Y\"/\"D\"/\"X\" or provide a proper \"formula\".')\n",
    "\n",
    "#     # Parse the formula\n",
    "#     varnames = patsy.ModelDesc.from_formula(formula).lhs_termlist + patsy.ModelDesc.from_formula(formula).rhs_termlist\n",
    "#     varnames = [v.name() for v in varnames]  # Convert to strings\n",
    "\n",
    "#     Y = varnames[0]  # Left-hand side of the formula\n",
    "\n",
    "#     if not isinstance(Y, (int, float)):  # Y is a variable (not a number)\n",
    "#         # Outcome\n",
    "#         Y = varnames[0]\n",
    "\n",
    "#         # Treatment indicator and covariates\n",
    "#         if len(varnames) == 1:  # Only Y\n",
    "#             D = X = None\n",
    "#             ignore_treat = 1\n",
    "\n",
    "#             if type == \"treat\":  # Y ~ 1, type(treat)\n",
    "#                 print('\"type = treat\" not allowed. Plot \"type = missing\" instead.')\n",
    "#                 type = \"missing\"\n",
    "\n",
    "#         elif len(varnames) == 2:\n",
    "#             if ignore_treat == 0:\n",
    "#                 D = varnames[1]\n",
    "#                 X = None\n",
    "#             else:\n",
    "#                 D = None\n",
    "#                 X = varnames[1]\n",
    "\n",
    "#         else:  # len(varnames) > 2\n",
    "#             if ignore_treat == 0:\n",
    "#                 D = varnames[1]\n",
    "#                 X = varnames[2:]\n",
    "#             else:\n",
    "#                 D = None\n",
    "#                 X = varnames[1:]\n",
    "\n",
    "#     elif isinstance(Y, (int, float)):  # Y is a number\n",
    "#         # Outcome\n",
    "#         Y = None\n",
    "\n",
    "#         # Treatment indicator and covariates\n",
    "#         if len(varnames) == 1:  # 1 ~ D/X\n",
    "#             if ignore_treat == 0:  # 1 ~ D\n",
    "#                 D = varnames[0]\n",
    "#                 X = None\n",
    "#             else:  # 1 ~ X\n",
    "#                 raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "#             if type in [\"missing\", \"miss\"]:  # 1 ~ variable, type(miss): not allowed\n",
    "#                 raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "#         elif len(varnames) == 2:  # 1 ~ D + X\n",
    "#             if ignore_treat == 0:  # 1 ~ D + X\n",
    "#                 D = varnames[0]\n",
    "#                 X = varnames[1]\n",
    "#             else:  # 1 ~ X\n",
    "#                 raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "#         else:  # len(varnames) > 2\n",
    "#             if ignore_treat == 0:\n",
    "#                 D = varnames[0]\n",
    "#                 X = varnames[1:]\n",
    "#             else:\n",
    "#                 raise ValueError(\"formula form not allowed.\")\n",
    "\n",
    "# else:  # No formula provided\n",
    "#     varnames = [Y, D, X]\n",
    "#     if D is None and X is None:  # Y = \"Y\", set type = \"miss\" as default\n",
    "#         if type == \"treat\":\n",
    "#             print('\"type = treat\" not allowed. Plot \"type = missing\" instead.')\n",
    "#             type = \"missing\"\n",
    "            \n",
    "#     varnames = [var for var in varnames if var is not None]\n",
    "\n",
    "    \n",
    "\n",
    "# # Check for incorrect variable names\n",
    "# for var in varnames:\n",
    "#     if var not in data.columns:\n",
    "#         raise ValueError(f'Variable \"{var}\" is not in the dataset.')\n",
    "\n",
    "# # Check index specification\n",
    "# if len(index) != 2 or sum([i in data.columns for i in index]) != 2:\n",
    "#     raise ValueError('\"index\" option misspecified. Try, for example, index = [\"unit.id\", \"time\"].')\n",
    "\n",
    "# # Assign index names\n",
    "# index_id = index[0]\n",
    "# index_time = index[1]\n",
    "\n",
    "# varV = None\n",
    "# nv = None\n",
    "\n",
    "# # Handle missing value report if needed\n",
    "# if report_missing:\n",
    "#     varV = [Y, D] + X if X is not None else [Y, D]\n",
    "#     nv = len(varV)\n",
    "\n",
    "#     # Create a matrix for missing values\n",
    "#     missing_data = pd.DataFrame({\n",
    "#         \"# Missing\": data[varV].isna().sum(),\n",
    "#         \"% Missing\": round(data[varV].isna().mean() * 100, 1)\n",
    "#     })\n",
    "\n",
    "#     print(missing_data)\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# # Set leave.gap logic\n",
    "# if by_cohort:\n",
    "#     leave_gap = 1\n",
    "\n",
    "# # Handle missing data based on leave_gap\n",
    "# if leave_gap == 0:\n",
    "#     data = data.dropna()\n",
    "# else:\n",
    "#     # Create row-wise missing value counts\n",
    "#     data['rowmiss'] = data.isna().sum(axis=1)\n",
    "#     data['minrowmiss'] = data.groupby(index_id)['rowmiss'].transform('min')\n",
    "\n",
    "#     # Drop units where all periods have missing values\n",
    "#     data = data[data['minrowmiss'] == 0]\n",
    "#     data = data.drop(columns=['rowmiss', 'minrowmiss'])\n",
    "\n",
    "\n",
    "# # Sort the data by index\n",
    "# data = data.sort_values(by=[index_id, index_time])\n",
    "\n",
    "# # Calculate time gap\n",
    "# min_time = data[index_time].min()\n",
    "# max_time = data[index_time].max()\n",
    "# unique_times = data[index_time].nunique()\n",
    "# time_gap = (max_time - min_time) / (unique_times - 1)\n",
    "# int_time_gap = int(time_gap)\n",
    "\n",
    "# # Calculate difference in time between consecutive observations\n",
    "# data['differencetime'] = data.groupby(index_id)[index_time].diff()\n",
    "# min_time_gap = data['differencetime'].min()\n",
    "# max_time_gap = data['differencetime'].max()\n",
    "\n",
    "# # Check for time gaps\n",
    "# if leave_gap == 0:\n",
    "#     if time_gap != min_time_gap or time_gap != int_time_gap:\n",
    "#         print(\"Time is not evenly distributed (possibly due to missing data).\\n\")\n",
    "\n",
    "# # Handle leave_gap == 1 (expand panel data)\n",
    "# if leave_gap == 1:\n",
    "#     # Calculate time differences within each unit\n",
    "#     data['differencetime'] = data.groupby(index_id)[index_time].diff()\n",
    "#     min_time_gap = data['differencetime'].min()\n",
    "#     max_time_gap = data['differencetime'].max()\n",
    "#     divide_differencetime = max_time_gap / min_time_gap if min_time_gap != 0 else np.inf\n",
    "\n",
    "#     if time_gap != min_time_gap or int_time_gap != time_gap:\n",
    "#         if min_time_gap != max_time_gap and min_time_gap != 1 and divide_differencetime == int(divide_differencetime):\n",
    "#             # Create all combinations of 'id' and 'time' based on the minimum time gap\n",
    "#             g = pd.DataFrame({\n",
    "#                 index_id: np.repeat(data[index_id].unique(), len(np.arange(min_time, max_time + min_time_gap, min_time_gap))),\n",
    "#                 index_time: np.tile(np.arange(min_time, max_time + min_time_gap, min_time_gap), data[index_id].nunique())\n",
    "#             })\n",
    "#             # Merge g with the data\n",
    "#             data = pd.merge(g, data, how='left', on=[index_id, index_time])\n",
    "#         else:\n",
    "#             g = pd.DataFrame({\n",
    "#                 index_id: np.repeat(data[index_id].unique(), len(np.arange(min_time, max_time + 1))),\n",
    "#                 index_time: np.tile(np.arange(min_time, max_time + 1), data[index_id].nunique())\n",
    "#             })\n",
    "#             data = pd.merge(g, data, how='left', on=[index_id, index_time])\n",
    "\n",
    "#     data.drop(columns=['differencetime'], inplace=True)\n",
    "\n",
    "# # Check for duplicated observations\n",
    "# unique_label = data[index_id].astype(str) + \"_\" + data[index_time].astype(str)\n",
    "# if unique_label.nunique() != len(data):\n",
    "#     raise ValueError(\"Unit and time variables do not uniquely identify all observations. Some may be duplicated.\")\n",
    "\n",
    "# # Limit units for gridOff\n",
    "# if data[index_id].nunique() > 300 and not gridOff and type != \"outcome\":\n",
    "#     print(\"Number of units is more than 300, setting 'gridOff = TRUE'.\")\n",
    "#     gridOff = True\n",
    "\n",
    "# if display_all == False and data[index_id].nunique() > 500:\n",
    "#     print(\"Number of units is more than 500, randomly selecting 500 units for display.\")\n",
    "#     sample_subject_ids = np.random.choice(data[index_id].unique(), 500, replace=False)\n",
    "#     data = data[data[index_id].isin(sample_subject_ids)]\n",
    "\n",
    "# ##-------------------------------##\n",
    "# ## Checking Other Parameters\n",
    "# ##-------------------------------## \n",
    "\n",
    "\n",
    "# # Check the 'type' option\n",
    "# if type not in [\"miss\", \"missing\", \"raw\", \"treat\", \"outcome\", \"bivar\", \"bivariate\"]:\n",
    "#     raise ValueError('\"type\" option misspecified.')\n",
    "\n",
    "# # Adjust for \"missing\" or \"miss\" types\n",
    "# if type in [\"missing\", \"miss\"]:\n",
    "#     type = \"treat\"\n",
    "#     ignore_treat = 1\n",
    "\n",
    "# # Adjust for \"raw\" type\n",
    "# if type == \"raw\":\n",
    "#     type = \"outcome\"\n",
    "\n",
    "# # Update cex settings based on group\n",
    "# if by_group or type == \"outcome\":\n",
    "#     cex_main_top = cex_main\n",
    "#     cex_main = cex_main_sub\n",
    "\n",
    "# # Handle axis labels\n",
    "# if cex_axis_x is None:\n",
    "#     cex_axis_x = cex_axis\n",
    "\n",
    "# if cex_axis_y is None:\n",
    "#     cex_axis_y = cex_axis\n",
    "\n",
    "# # Check if treatment indicator is available\n",
    "# if D is None and ignore_treat == 0:\n",
    "#     print(\"No treatment indicator.\")\n",
    "#     ignore_treat = 1\n",
    "\n",
    "# # Check if outcomes are available for certain types\n",
    "# if Y is None and type in [\"outcome\", \"bivar\", \"bivariate\"]:\n",
    "#     raise ValueError(\"No outcomes.\")\n",
    "\n",
    "# # Validate axis.lab option\n",
    "# if axis_lab not in [\"both\", \"unit\", \"time\", \"off\"]:\n",
    "#     raise ValueError('\"axis.lab\" option misspecified. Try, for example, axis.lab = [\"both\", \"unit\", \"time\", \"off\"].')\n",
    "\n",
    "# # Validate axis.lab.gap\n",
    "# if any(np.array(axis_lab_gap) < 0):\n",
    "#     raise ValueError('\"axis.lab.gap\" should be greater than or equal to 0.')\n",
    "\n",
    "# # Validate legend labels\n",
    "# if legend_labs is not None:\n",
    "#     legend_labs = [str(lab) for lab in legend_labs]\n",
    "\n",
    "# # Validate outcome.type\n",
    "# if outcome_type not in [\"continuous\", \"discrete\"]:\n",
    "#     raise ValueError('\"outcome.type\" option misspecified. Try, for example, outcome_type = [\"continuous\", \"discrete\"].')\n",
    "\n",
    "# # Handle treatment indicator checks\n",
    "# d_levels = None\n",
    "# d_bi = False\n",
    "\n",
    "# # Without ignore.treat\n",
    "# if ignore_treat == 0:\n",
    "#     if leave_gap == 0:\n",
    "#         if not pd.api.types.is_numeric_dtype(data[D]):\n",
    "#             raise ValueError(\"Treatment indicator should be a numeric value.\")\n",
    "\n",
    "#     d_levels = sorted(data[D].unique())\n",
    "#     n_levels = len(d_levels)\n",
    "#     d_bi = d_levels == [0, 1] and n_levels == 2  # Binary treatment check\n",
    "\n",
    "#     if not d_bi and by_cohort:\n",
    "#         raise ValueError('Option \"by.cohort = TRUE\" works only with dummy treatment variable')\n",
    "\n",
    "#     if outcome_type == \"discrete\":\n",
    "#         y_levels = sorted(data[Y].unique())\n",
    "\n",
    "#     if n_levels == 1:\n",
    "#         print(\"Only one treatment level...\")\n",
    "#         ignore_treat = 1\n",
    "#     else:\n",
    "#         if not d_bi:\n",
    "#             print(f\"{n_levels} treatment levels.\")\n",
    "\n",
    "#     # Treatment type validation\n",
    "#     if treat_type is not None:\n",
    "#         if treat_type not in [\"discrete\", \"continuous\"]:\n",
    "#             raise ValueError('\"treat.type\" must be \"discrete\" or \"continuous\".')\n",
    "\n",
    "#         if treat_type == \"discrete\" and n_levels >= 5:\n",
    "#             print(\"Too many treatment levels; treat as continuous.\")\n",
    "#             treat_type = \"continuous\"\n",
    "\n",
    "#         if treat_type == \"continuous\" and n_levels <= 4:\n",
    "#             print(\"Too few treatment levels; consider setting treat_type = 'discrete'.\")\n",
    "#     else:\n",
    "#         treat_type = \"continuous\" if n_levels > 5 else \"discrete\"\n",
    "\n",
    "# else:  # ignore_treat == 1\n",
    "#     n_levels = 0\n",
    "#     treat_type = \"discrete\"\n",
    "\n",
    "# # Check shade.post type\n",
    "# if not isinstance(shade_post, (bool, int)):\n",
    "#     raise ValueError('Incorrect type for option \"shade.post\".')\n",
    "\n",
    "# ## ------------------------ ##\n",
    "# ## parsing data.            ##\n",
    "# ## ------------------------ ##\n",
    "\n",
    "# # Parsing data\n",
    "# raw_id = sorted(data[index_id].unique())\n",
    "# raw_time = sorted(data[index_time].unique())\n",
    "# N = len(raw_id)\n",
    "# TT = len(raw_time)\n",
    "# N\n",
    "\n",
    "# # Handling input.id\n",
    "# input_id = None\n",
    "# if id is not None:\n",
    "#     if show_id is not None:\n",
    "#         print(\"Using specified id.\")\n",
    "#     remove_id = np.setdiff1d(id, raw_id)\n",
    "#     if len(remove_id) != 0:\n",
    "#         print(f\"List of units removed from dataset: {remove_id}\")\n",
    "#         input_id = np.intersect1d(sorted(id), raw_id)\n",
    "#     else:\n",
    "#         input_id = sorted(id)\n",
    "# else:\n",
    "#     if show_id is not None:\n",
    "#         if len(show_id) > N:\n",
    "#             raise ValueError(\"Length of 'show.id' should not be larger than total number of units.\")\n",
    "#         if not isinstance(show_id[0], (int, float)):\n",
    "#             raise ValueError(\"'show.id' option misspecified. Try, for example, show_id = range(1, 100).\")\n",
    "#         if any(show_id > N):\n",
    "#             raise ValueError(\"Some specified units are not in the data.\")\n",
    "#         if len(np.unique(show_id)) != len(show_id):\n",
    "#             raise ValueError(\"Repeated values in 'show.id' option.\")\n",
    "#         input_id = raw_id[show_id]\n",
    "#     else:\n",
    "#         input_id = raw_id\n",
    "\n",
    "# input_id[:4]\n",
    "\n",
    "# # Store variable names\n",
    "# data_old = data.copy()\n",
    "# Yname = Y\n",
    "# Dname = D\n",
    "\n",
    "# # Check missing values\n",
    "# data['rowmiss'] = data.isna().sum(axis=1)\n",
    "# rowmissname = 'rowmiss'\n",
    "\n",
    "# # Subset data if necessary\n",
    "# if len(input_id) != len(raw_id):\n",
    "#     data = data[data[index_id].isin(input_id)]\n",
    "#     N = len(input_id)\n",
    "\n",
    "# # Initialize variables\n",
    "# Y, D, I, M = None, None, None, None\n",
    "\n",
    "# # Handling leave.gap == 0 (Balanced Panel)\n",
    "# if leave_gap == 0:\n",
    "#     if len(data) != TT * N:  # Unbalanced panel\n",
    "#         data[index_id] = pd.factorize(data[index_id])[0] + 1\n",
    "#         data[index_time] = pd.factorize(data[index_time])[0] + 1\n",
    "\n",
    "#         if Yname is not None:\n",
    "#             Y = np.full((TT, N), np.nan)\n",
    "#         I = np.zeros((TT, N))\n",
    "\n",
    "#         if ignore_treat == 0:\n",
    "#             D = np.zeros((TT, N))\n",
    "\n",
    "#         for i in range(len(data)):\n",
    "#             if Yname is not None:\n",
    "#                 Y[data.iloc[i][index_time] - 1, data.iloc[i][index_id] - 1] = data.iloc[i][Yname]\n",
    "\n",
    "#             if ignore_treat == 0:\n",
    "#                 D[data.iloc[i][index_time] - 1, data.iloc[i][index_id] - 1] = data.iloc[i][Dname]\n",
    "\n",
    "#             I[data.iloc[i][index_time] - 1, data.iloc[i][index_id] - 1] = 1\n",
    "\n",
    "#     else:  # Balanced panel\n",
    "#         I = np.ones((TT, N))\n",
    "#         if Yname is not None:\n",
    "#             Y = data[Yname].values.reshape((TT, N), order='F')\n",
    "#         if ignore_treat == 0:\n",
    "#             D = data[Dname].values.reshape((TT, N), order='F')\n",
    "\n",
    "# else:  # leave.gap == 1 (Balanced panel with missing data)\n",
    "#     data[index_id] = pd.factorize(data[index_id])[0] + 1\n",
    "#     data[index_time] = pd.factorize(data[index_time])[0] + 1\n",
    "\n",
    "#     M = np.zeros((TT, N))\n",
    "#     for i in range(len(data)):\n",
    "#         M[data.iloc[i][index_time] - 1, data.iloc[i][index_id] - 1] = data.iloc[i][rowmissname]\n",
    "\n",
    "#     if Yname is not None:\n",
    "#         Y = np.full((TT, N), np.nan)\n",
    "#     I = np.zeros((TT, N))\n",
    "#     if ignore_treat == 0:\n",
    "#         D = np.zeros((TT, N))\n",
    "\n",
    "#     for i in range(len(data)):\n",
    "#         if Yname is not None:\n",
    "#             Y[data.iloc[i][index_time] - 1, data.iloc[i][index_id] - 1] = data.iloc[i][Yname]\n",
    "\n",
    "#         if ignore_treat == 0:\n",
    "#             D[data.iloc[i][index_time] - 1, data.iloc[i][index_id] - 1] = data.iloc[i][Dname]\n",
    "\n",
    "#         I[data.iloc[i][index_time] - 1, data.iloc[i][index_id] - 1] = 1\n",
    "\n",
    "# # Handling collapse.history == TRUE\n",
    "# if collapse_history:\n",
    "#     D_f = np.vstack([D, I]) if M is None else np.vstack([D, I, M])\n",
    "\n",
    "#     D_d = pd.DataFrame(D_f.T)\n",
    "#     ff = D_d.groupby(list(D_d.columns)).size().reset_index(name='COUNT')\n",
    "\n",
    "#     D = ff.iloc[:, :TT].T.values\n",
    "#     I = ff.iloc[:, TT:2 * TT].T.values\n",
    "\n",
    "#     if M is None:\n",
    "#         input_id = ff.iloc[:, 2 * TT].values\n",
    "#     else:\n",
    "#         M = ff.iloc[:, 2 * TT:3 * TT].T.values\n",
    "#         input_id = ff.iloc[:, 3 * TT].values\n",
    "\n",
    "#     N = len(input_id)\n",
    "\n",
    "#     # Sort by cohort size\n",
    "#     D_id = np.column_stack((np.arange(1, N + 1), input_id))\n",
    "#     D_id = D_id[D_id[:, 1].argsort()[::-1]]\n",
    "#     D_id_vec = D_id[:, 0].astype(int) - 1\n",
    "\n",
    "#     input_id = D_id[:, 1]\n",
    "#     D = D[:, D_id_vec]\n",
    "#     I = I[:, D_id_vec]\n",
    "#     if M is not None:\n",
    "#         M = M[:, D_id_vec]\n",
    "\n",
    "# D_old = D.copy()\n",
    "\n",
    "# # Binary treatment indicator\n",
    "# if not ignore_treat and d_bi:\n",
    "#     if len(np.unique(D_old)) > 2:\n",
    "#         D[D > 1] = 1\n",
    "\n",
    "#     # Once treated, always treated\n",
    "#     D = np.apply_along_axis(lambda x: np.cumsum(np.nan_to_num(x)) + (x == 0).astype(int) * 0, axis=0, arr=D)\n",
    "#     co_total_all = TT - D.sum(axis=0)\n",
    "#     D = (D > 0).astype(int)\n",
    "\n",
    "#     tr_pos = np.where(D[TT - 1] == 1)[0]\n",
    "#     T0 = np.sum(D == 0, axis=0)[tr_pos] + 1\n",
    "#     T1 = np.sum(D == 1, axis=0)[tr_pos]\n",
    "\n",
    "#     T1[T1 > 1] = 0\n",
    "#     co_total = co_total_all[tr_pos]\n",
    "#     DID = len(np.unique(T0)) == 1\n",
    "\n",
    "#     if np.sum(np.abs(D_old[I == 1] - D[I == 1])) == 0:\n",
    "#         staggered = 1\n",
    "#     else:\n",
    "#         DID = 0\n",
    "#         staggered = 0\n",
    "# else:\n",
    "#     DID = 0\n",
    "#     staggered = 1\n",
    "\n",
    "# ########################################\n",
    "# ## unified labels:\n",
    "# ##  -200 for missing\n",
    "# ##  -1 for control condition (or observed)\n",
    "# ##   0 for treated pre\n",
    "# ##   1 for treated post  \n",
    "# ########################################\n",
    "\n",
    "\n",
    "# obs_missing = None\n",
    "# if leave_gap == 0:\n",
    "#     if ignore_treat == 0 and d_bi == 1:  # binary, and without ignore_treat\n",
    "#         con1 = type == \"treat\" and pre_post is True\n",
    "#         con2 = type == \"outcome\" and by_group is False\n",
    "\n",
    "#         if staggered == 1 and (con1 or con2):  # DID type data\n",
    "#             tr = D[(TT-1), :] == 1  # cross-sectional: treated unit\n",
    "\n",
    "#             id_tr = np.where(tr == 1)[0]\n",
    "#             id_co = np.where(tr == 0)[0]\n",
    "\n",
    "#             D_tr = D[:, id_tr]\n",
    "#             I_tr = I[:, id_tr]\n",
    "#             Y_tr = Y_co = None\n",
    "#             if type == \"outcome\":\n",
    "#                 Y_tr = Y[:, id_tr]\n",
    "#                 Y_co = Y[:, id_co]\n",
    "\n",
    "#             Ntr = np.sum(tr)\n",
    "#             Nco = N - Ntr\n",
    "\n",
    "#             # 1. control group: -1\n",
    "#             obs_missing = np.full((TT, N), -1)\n",
    "#             # 2. add treated units\n",
    "#             obs_missing[:, id_tr] = D[:, id_tr]\n",
    "#             # 3. set missing values\n",
    "#             obs_missing[np.where(I == 0)] = -200  # missing -200; I==0: missings in unbalanced panel\n",
    "\n",
    "#             unit_type = np.full(N, 1)  # 1 for control; 2 for treated; 3 for reversal\n",
    "#             unit_type[id_tr] = 2\n",
    "\n",
    "#         else:\n",
    "#             unit_type = np.full(N, np.nan)  # 1 for control; 2 for treated; 3 for reversal\n",
    "\n",
    "#             for i in range(N):\n",
    "#                 di = D_old[:, i]\n",
    "#                 ii = I[:, i]\n",
    "\n",
    "#                 if len(np.unique(di[np.where(ii == 1)])) == 1:  # treated or control\n",
    "#                     if 0 in np.unique(di[np.where(ii == 1)]):\n",
    "#                         unit_type[i] = 1  # always control\n",
    "#                     else:\n",
    "#                         unit_type[i] = 2  # always treated\n",
    "#                 else:\n",
    "#                     unit_type[i] = 3  # control to treated / treated to control\n",
    "\n",
    "#             # 1. using D_old  \n",
    "#             obs_missing = D_old.copy()\n",
    "#             # 2. set controls\n",
    "#             obs_missing[np.where(D_old == 0)] = -1  # under control\n",
    "#             # 3. set missing \n",
    "#             obs_missing[np.where(I == 0)] = -200  # missing\n",
    "\n",
    "#         obs_missing_treat = obs_missing.copy()\n",
    "#         if len(np.unique(D_old)) > 2:\n",
    "#             obs_missing[np.where(obs_missing > 1)] = 1\n",
    "\n",
    "#     else:  # either not binary (>2 treatment levels) or ignore_treat == 1\n",
    "#         if n_levels > 2 and type == \"treat\":  # >2 treatment levels\n",
    "#             obs_missing = D.copy()\n",
    "#             obs_missing[np.where(I == 0)] = np.nan\n",
    "#         else:\n",
    "#             obs_missing = np.full((TT, N), -1)\n",
    "#             obs_missing[np.where(I == 0)] = -200  # missing\n",
    "#             ignore_treat = 1\n",
    "\n",
    "# elif leave_gap == 1:\n",
    "#     if ignore_treat == 0 and d_bi == 1:  # binary, and without ignore_treat\n",
    "#         con1 = type == \"treat\" and pre_post is True\n",
    "#         con2 = type == \"outcome\" and by_group is False\n",
    "\n",
    "#         if staggered == 1 and (con1 or con2):  # DID type data\n",
    "#             tr = D[TT, :] == 1  # cross-sectional: treated unit\n",
    "\n",
    "#             id_tr = np.where(tr == 1)[0]\n",
    "#             id_co = np.where(tr == 0)[0]\n",
    "\n",
    "#             D_tr = D[:, id_tr]\n",
    "#             I_tr = I[:, id_tr]\n",
    "#             Y_tr = Y_co = None\n",
    "\n",
    "#             if type == \"outcome\":\n",
    "#                 Y_tr = Y[:, id_tr]\n",
    "#                 Y_co = Y[:, id_co]\n",
    "\n",
    "#             Ntr = np.sum(tr)\n",
    "#             Nco = N - Ntr\n",
    "\n",
    "#             # 1. control group: -1\n",
    "#             obs_missing = np.full((TT, N), -1)\n",
    "#             # 2. add treated units\n",
    "#             obs_missing[:, id_tr] = D[:, id_tr]\n",
    "#             # 3. set missing values\n",
    "#             obs_missing[np.where(I == 0)] = -200  # missing -200\n",
    "#             obs_missing[np.where(M != 0)] = -200\n",
    "\n",
    "#             unit_type = np.full(N, 1)  # 1 for control; 2 for treated; 3 for reversal\n",
    "#             unit_type[id_tr] = 2\n",
    "\n",
    "#         else:\n",
    "#             unit_type = np.full(N, np.nan)  # 1 for control; 2 for treated; 3 for reversal\n",
    "\n",
    "#             for i in range(N):\n",
    "#                 di = D_old[:, i]\n",
    "#                 ii = I[:, i]  # I: observed or missing\n",
    "\n",
    "#                 if len(np.unique(di[np.where(ii == 1)])) == 1:  # treated or control\n",
    "#                     if 0 in np.unique(di[np.where(ii == 1)]):\n",
    "#                         unit_type[i] = 1  # control\n",
    "#                     else:\n",
    "#                         unit_type[i] = 2  # treated\n",
    "#                 elif len(np.unique(di[np.where(ii == 1)])) == 2 and np.nan in np.unique(di[np.where(ii == 1)]):\n",
    "#                     if 0 in np.unique(di[np.where(ii == 1)]):\n",
    "#                         unit_type[i] = 1  # control\n",
    "#                     else:\n",
    "#                         unit_type[i] = 2  # treated\n",
    "#                 else:\n",
    "#                     unit_type[i] = 3  # control to treated / treated to control / NA 0 1 / NA 1 0\n",
    "\n",
    "#             # 1. using D_old  \n",
    "#             obs_missing = D_old.copy()\n",
    "#             # 2. set controls\n",
    "#             obs_missing[np.where(D_old == 0)] = -1  # under control\n",
    "#             # 3. set missing \n",
    "#             obs_missing[np.where(I == 0)] = -200  # missing\n",
    "#             obs_missing[np.where(M != 0)] = -200\n",
    "\n",
    "#         obs_missing_treat = obs_missing.copy()\n",
    "#         if len(np.unique(D_old)) > 2:\n",
    "#             obs_missing[np.where(obs_missing > 1)] = 1\n",
    "\n",
    "#     else:  # either not binary (>2 treatment levels) or ignore_treat == 1\n",
    "#         if n_levels > 2 and type == \"treat\":  # >2 treatment levels\n",
    "#             obs_missing = D.copy()\n",
    "#             obs_missing[np.where(I == 0)] = -200\n",
    "#             obs_missing[np.where(M != 0)] = -200\n",
    "#         else:\n",
    "#             obs_missing = np.full((TT, N), -1)\n",
    "#             obs_missing[np.where(I == 0)] = -200\n",
    "#             obs_missing[np.where(M != 0)] = -200\n",
    "#             ignore_treat = 1\n",
    "\n",
    "# # Setting column and row names\n",
    "# obs_missing = pd.DataFrame(obs_missing, columns=input_id, index=raw_time)\n",
    "\n",
    "# # Setting time and id for the final output\n",
    "# time = raw_time\n",
    "# id = input_id\n",
    "\n",
    "# # Check if xlim is valid\n",
    "# if xlim is not None:\n",
    "#     if not isinstance(xlim, list) or not all(isinstance(i, (int, float)) for i in xlim):\n",
    "#         raise ValueError('Some element in \"xlim\" is not numeric.')\n",
    "#     elif len(xlim) != 2:\n",
    "#         raise ValueError('\"xlim\" must be of length 2.')\n",
    "\n",
    "# # Check if ylim is valid\n",
    "# if type not in [\"bivar\", \"bivariate\"]:\n",
    "#     if ylim is not None:\n",
    "#         if not isinstance(ylim, list) or not all(isinstance(i, (int, float)) for i in ylim):\n",
    "#             raise ValueError('Some element in \"ylim\" is not numeric.')\n",
    "#         elif len(ylim) != 2:\n",
    "#             raise ValueError('\"ylim\" must be of length 2.')\n",
    "\n",
    "# # Check if xlab is valid\n",
    "# if xlab is not None:\n",
    "#     if not isinstance(xlab, str):\n",
    "#         raise ValueError('\"xlab\" is not a string.')\n",
    "#     else:\n",
    "#         xlab = xlab\n",
    "\n",
    "# # Check if ylab is valid\n",
    "# if ylab is not None:\n",
    "#     if not isinstance(ylab, str):\n",
    "#         raise ValueError('\"ylab\" is not a string.')\n",
    "#     else:\n",
    "#         ylab = ylab\n",
    "\n",
    "# # Check if legendOff is a valid logical flag\n",
    "# if not isinstance(legendOff, (bool, int)):\n",
    "#     raise ValueError('\"legendOff\" is not a logical flag.')\n",
    "\n",
    "# # Check if gridOff is a valid logical flag\n",
    "# if not isinstance(gridOff, (bool, int)):\n",
    "#     raise ValueError('\"gridOff\" is not a logical flag.')\n",
    "\n",
    "# # Check if main is valid\n",
    "# if main is not None:\n",
    "#     if not isinstance(main, str):\n",
    "#         raise ValueError('\"main\" is not a string.')\n",
    "#     else:\n",
    "#         main = main\n",
    "\n",
    "# # Handle axis.lab.angle\n",
    "# if axis_lab_angle is not None:\n",
    "#     angle = axis_lab_angle\n",
    "#     x_v, x_h = 1, 1\n",
    "# else:\n",
    "#     if axis_adjust:\n",
    "#         angle = 45\n",
    "#         x_v, x_h = 1, 1\n",
    "#     else:\n",
    "#         angle = 0\n",
    "#         x_v = 0\n",
    "#         if type == \"treat\":\n",
    "#             x_h = 0.5\n",
    "#         else:\n",
    "#             x_h = 0\n",
    "\n",
    "# # Type of plots\n",
    "# if not isinstance(time[0], (int, float)):\n",
    "#     time = list(range(1, TT + 1))\n",
    "\n",
    "# # Periods to show\n",
    "# if xlim:\n",
    "#     show = [i for i, t in enumerate(time) if xlim[0] <= t <= xlim[1]]\n",
    "# else:\n",
    "#     show = list(range(len(time)))\n",
    "\n",
    "# nT = len(show)\n",
    "# time_label = [raw_time[i] for i in show]\n",
    "# T_b = list(range(1, len(show) + 1))\n",
    "\n",
    "# # Labels\n",
    "# N_b = list(range(1, N + 1))\n",
    "# if type == \"treat\":\n",
    "#     if axis_lab == \"both\":\n",
    "#         if len(axis_lab_gap) == 2:\n",
    "#             x_gap, y_gap = axis_lab_gap\n",
    "#         else:\n",
    "#             x_gap = y_gap = axis_lab_gap[0]\n",
    "#     else:\n",
    "#         x_gap = y_gap = axis_lab_gap[0]\n",
    "    \n",
    "#     if y_gap != 0:\n",
    "#         N_b = list(range(N, 0, -(y_gap + 1)))\n",
    "# else:\n",
    "#     x_gap = axis_lab_gap[0]\n",
    "\n",
    "# if x_gap != 0:\n",
    "#     T_b = list(range(1, len(show) + 1, x_gap + 1))\n",
    "\n",
    "# # Legend on/off\n",
    "# legend_pos = \"none\" if legendOff else \"bottom\"\n",
    "\n",
    "# # # Output for debugging (optional)\n",
    "# # print(f\"xlab: {xlab}, ylab: {ylab}, main: {main}\")\n",
    "# # print(f\"Legend Position: {legend_pos}\")\n",
    "# # print(f\"Show time periods: {show}\")\n",
    "# # print(f\"Angle: {angle}, x_v: {x_v}, x_h: {x_h}\")\n",
    "\n",
    "\n",
    "# if treat == 'treat'\n",
    "\n",
    "# # Conditional logic for labels and title\n",
    "# if xlab is None:\n",
    "#     xlab = index[1]\n",
    "# elif xlab == \"\":\n",
    "#     xlab = None\n",
    "\n",
    "# if ylab is None:\n",
    "#     ylab = index[0]\n",
    "#     if collapse_history:\n",
    "#         ylab = \"Number of Units\"\n",
    "# elif ylab == \"\":\n",
    "#     ylab = None\n",
    "\n",
    "# if main is None:\n",
    "#     if collapse_history:\n",
    "#         main = \"Unique Treatment Histories\"\n",
    "#     else:\n",
    "#         main = \"Treatment Status\" if ignore_treat == 0 else \"Missing Values\"\n",
    "# elif main == \"\":\n",
    "#     main = None\n",
    "\n",
    "# # Generate units and periods\n",
    "# units = np.repeat(np.arange(N, 0, -1), TT)\n",
    "# period = np.tile(np.arange(1, TT + 1), N)\n",
    "\n",
    "# # Extract the selected rows and convert to a NumPy array (if not already)\n",
    "# m = np.array(obs_missing.iloc[show, :])\n",
    "\n",
    "# # Flatten the array, remove NaN values, and find the unique values\n",
    "# all_values = np.unique(m[~np.isnan(m)])\n",
    "\n",
    "\n",
    "# colors = []\n",
    "# label = []\n",
    "# breaks = []\n",
    "# # Setting colors and labels based on treatment type and level\n",
    "# if ((not d_bi) and (ignore_treat == 0)):  # More than 2 treatment levels\n",
    "\n",
    "#     tr_colors = [\"#66C2A5\", \"#FC8D62\", \"#8DA0CB\", \"#E78AC3\", \"#A6D854\", \"#FFD92F\"]\n",
    "    \n",
    "#     if treat_type == \"discrete\":\n",
    "#         for i in range(n_levels):\n",
    "#             breaks.append(d_levels[i])\n",
    "#             # label.append(f\"Treatment level: {d_levels[i]}\")  # If you want to include \"Treatment level\"\n",
    "#             label.append(f\"{d_levels[i]}\")\n",
    "#         colors = tr_colors[:n_levels]\n",
    "#     else:\n",
    "#         print(\"Continuous treatment.\")\n",
    "#         interval = (max(all_values) - min(all_values)) / 4\n",
    "#         for i in range(5):\n",
    "#             breaks.append(min(all_values) + i * interval)\n",
    "#         colors = [\"#c6dbef\", \"#4292c6\", \"#1f78b4\", \"#08519c\", \"#042b53\"]\n",
    "\n",
    "#     if -200 in all_values:\n",
    "#         colors.append(\"#FFFFFF\")\n",
    "#         breaks.append(-200)\n",
    "#         label.append(\"Missing\")\n",
    "# else:  # Binary treatment indicator\n",
    "#     if (0 in all_values):  # General DID type data\n",
    "        \n",
    "        \n",
    "#         if -1 in all_values:\n",
    "#             colors.append(\"#B0C4DE\")\n",
    "#             breaks.append(-1)\n",
    "#             label.append(\"Controls\")\n",
    "        \n",
    "#         colors.append(\"#4671D5\")\n",
    "#         breaks.append(0)\n",
    "#         label.append(\"Treated (Pre)\")\n",
    "\n",
    "#         if 1 in all_values:\n",
    "#             colors.append(\"#06266F\")\n",
    "#             breaks.append(1)\n",
    "#             label.append(\"Treated (Post)\")\n",
    "            \n",
    "#     else:\n",
    "    \n",
    "#         # Control condition\n",
    "#         if -1 in all_values:\n",
    "#             colors.append(\"#B0C4DE\")\n",
    "#             breaks.append(-1)\n",
    "#             if ignore_treat == 0:\n",
    "#                 # Assuming pre_post is not used, so directly appending \"Under Control\"\n",
    "#                 label.append(\"Under Control\")\n",
    "#             else:\n",
    "#                 label.append(\"Observed\")\n",
    "\n",
    "#         # Treated condition\n",
    "#         if 1 in all_values:\n",
    "#             colors.append(\"#06266F\")\n",
    "#             breaks.append(1)\n",
    "#             # Assuming pre_post is not used, so directly appending \"Under Treatment\"\n",
    "#             label.append(\"Under Treatment\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "#     # Additional missing value handling\n",
    "#     if -200 in all_values:\n",
    "#         colors.append(\"#FFFFFF\")\n",
    "#         breaks.append(-200)\n",
    "#         label.append(\"Missing\")\n",
    "        \n",
    "        \n",
    "    \n",
    "#     # If the condition is met, execute the following:\n",
    "#     if len(id) > 1 and ignore_treat == 0 and d_bi:\n",
    "\n",
    "#         if by_timing:\n",
    "#             # Get indices for control units (unit_type == 1)\n",
    "#             co_seq = np.where(unit_type == 1)[0]\n",
    "#             # Get indices for treated units (not control)\n",
    "#             tr_seq = np.setdiff1d(np.arange(N), co_seq)\n",
    "\n",
    "#             # Create a DataFrame similar to cbind in R\n",
    "#             dataT0 = pd.DataFrame({\n",
    "#                 'id': tr_seq,\n",
    "#                 'T0': T0,\n",
    "#                 'co_total': co_total\n",
    "#             })\n",
    "\n",
    "#             # Sort by T0, co_total, and id\n",
    "#             dataT0 = dataT0.sort_values(by=['T0', 'co_total', 'id'])\n",
    "\n",
    "#             # Extract the sorted ids\n",
    "#             tr_seq = dataT0['id'].values\n",
    "#             missing_seq = np.concatenate((tr_seq, co_seq))\n",
    "\n",
    "#             # Reorder the matrix 'm' and 'id'\n",
    "#             m = m[:, missing_seq]\n",
    "#             id = np.array(id)[missing_seq]\n",
    "\n",
    "\n",
    "# # User-defined color setting\n",
    "# if color is not None:\n",
    "#     if treat_type == \"discrete\":  # Discrete treatment indicator\n",
    "#         if len(col) == len(color):\n",
    "#             print(f\"Specified colors in the order of: {', '.join(labels)}.\")\n",
    "#             col = color\n",
    "#         else:\n",
    "#             raise ValueError(f\"Length of 'color' should be equal to {len(col)}.\")\n",
    "\n",
    "# # User-defined legend labels\n",
    "# if legend_labs is not None:\n",
    "#     if treat_type == \"discrete\":  # Discrete treatment indicator\n",
    "#         if len(legend_labs) != len(label):\n",
    "#             print(\"Warning: Incorrect number of labels in the legends. Using default.\")\n",
    "#         else:\n",
    "#             print(f\"Specified labels in the order of: {', '.join(legend_labs)}.\")\n",
    "#             label = legend_labs\n",
    "\n",
    "\n",
    "# # Create the data frame for plotting\n",
    "# data = pd.DataFrame({\n",
    "#     'units': units,\n",
    "#     'period': period,\n",
    "#     'res': m.T[::-1, :].ravel()\n",
    "# })\n",
    "\n",
    "# # Remove NA values if leave.gap is 0 (adjust according to your logic)\n",
    "# leave_gap = 0\n",
    "# if leave_gap == 0:\n",
    "#     data.dropna(inplace=True)\n",
    "\n",
    "# # id = list( reversed( id ) )  # Reverse ID list\n",
    "\n",
    "# # Check if N >= 200\n",
    "# if m.shape[1] >= 200:\n",
    "#     if axis_lab == \"both\":\n",
    "#         axis_lab = \"time\"\n",
    "#     elif axis_lab == \"unit\":\n",
    "#         axis_lab = \"off\"\n",
    "\n",
    "# # Set background color\n",
    "# if background is not None:\n",
    "#     grid_color = border_color = background_color = legend_color = background\n",
    "# else:\n",
    "#     grid_color = border_color = background_color = legend_color = \"grey\"\n",
    "\n",
    "\n",
    "# # Plot with seaborn/matplotlib\n",
    "# if ((by_timing == True) and ( pre_post == False ) ):\n",
    "#     print('by timing')\n",
    "#     data2plot = data.pivot(index='units', columns='period', values='res')\n",
    "\n",
    "#     # Reverse the id values\n",
    "# #     id = id[::-1]\n",
    "# elif pre_post == True:\n",
    "#     data2plot = data.pivot(index='units', columns='period', values='res') \\\n",
    "#                     .sort_values(['units'], ascending = True)\n",
    "#     print('jola')\n",
    "# #     id = id[::-1]\n",
    "# else:\n",
    "#     data2plot = data.pivot(index='units', columns='period', values='res')\n",
    "    \n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap( data2plot, \n",
    "#             cmap=sns.color_palette(colors, as_cmap=True), cbar=False, \n",
    "#            linewidths=0.5, linecolor='white')\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel(f'{xlab}' if axis_lab in [\"both\", \"time\"] else \"Time\")\n",
    "# plt.ylabel(f'{ylab}' if axis_lab in [\"both\", \"unit\"] else \"Unit\")\n",
    "# plt.title(f'{main}', fontsize = cex_main)\n",
    "\n",
    "# # Manually setting grid and background colors\n",
    "# if not gridOff:\n",
    "#     plt.gca().set_facecolor(grid_color)\n",
    "\n",
    "# # Adjusting legend\n",
    "# if len(breaks) < 3:\n",
    "#     control_patch = mpatches.Patch(color=colors[0], label=label[0])\n",
    "#     treatme_patch = mpatches.Patch(color=colors[1], label=label[1])\n",
    "#     plt.legend(handles=[ control_patch, treatme_patch ], title=\"\", frameon=False, \n",
    "#                loc='lower center',  bbox_to_anchor=(0.5, -0.15), ncol=2 )\n",
    "    \n",
    "# if len(breaks) == 3:\n",
    "#     control_patch = mpatches.Patch(color=colors[0], label=label[0])\n",
    "#     treatme_patch = mpatches.Patch(color=colors[1], label=label[1])\n",
    "#     new_treatme_patch = mpatches.Patch(color=colors[2], label=label[2])\n",
    "#     plt.legend(handles=[ control_patch, treatme_patch, new_treatme_patch ], title=\"\", frameon=False, \n",
    "#                loc='lower center',  bbox_to_anchor=(0.5, -0.15), ncol=3 )\n",
    "\n",
    "# # Customizing the x and y axis based on the condition\n",
    "# if axis_lab == \"both\":\n",
    "#     plt.xticks(ticks= np.array(T_b) - 0.5 , labels=[time_label[b-1] for b in T_b], \n",
    "#                rotation=angle, ha='center', fontsize= cex_axis_x )\n",
    "#     plt.yticks(ticks= np.array(N_b) - 0.5 , labels=[id[ b-1 ] for b in N_b], \n",
    "#                rotation=angle, fontsize= cex_axis_y)\n",
    "\n",
    "# elif axis_lab == \"unit\":\n",
    "#     plt.xticks(ticks= np.array(T_b) - 0.5, labels=None, fontsize= cex_axis_x)\n",
    "#     plt.yticks(ticks= np.array(N_b) - 0.5 , labels=[id[ b-1 ] for b in N_b], \n",
    "#                rotation=angle, fontsize= cex_axis_y)\n",
    "    \n",
    "# elif axis_lab == \"time\":\n",
    "#     plt.xticks(ticks= np.array(T_b) - 0.5 , labels=[time_label[b-1] for b in T_b], \n",
    "#                rotation=angle, ha='center', fontsize= cex_axis_x )\n",
    "#     plt.yticks(ticks= [] )\n",
    "    \n",
    "# elif axis_lab == \"off\":\n",
    "#     plt.xticks(ticks=[], labels=[])\n",
    "#     plt.yticks(ticks=[], labels=[])\n",
    "\n",
    "# # Setting legend\n",
    "# if ((len(breaks) >= 4) and (len(breaks) < 6)):\n",
    "#     plt.legend(ncol=2, loc='lower center')\n",
    "\n",
    "# # plt.ylim(0, 0)\n",
    "# # Display the plot\n",
    "# # Hide x and y axis tick lines\n",
    "# plt.tick_params(axis='x', which='both', length=0)  # Hide x-axis ticks\n",
    "# plt.tick_params(axis='y', which='both', length=0)  # Hide y-axis ticks\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
